{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushpatra11/RLU_UoM/blob/main/COM64102_Assignment_a85716ap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf52PGSevKXY"
      },
      "source": [
        "# Assignment Brief: Probabilistic Programming and Active Learning\n",
        "\n",
        "## Deadline: May 7, 2025, 17:00 GMT\n",
        "\n",
        "## Number of marks available: 50\n",
        "\n",
        "This coursework is made of two parts. In the first part, you will use probabilistic programming to perform Bayesian inference in different models. In the second part, you will use uncertainty to guide datapoint selection to create a dataset to train a machine learning model.\n",
        "\n",
        "### Please READ the whole assignment first, before starting to work on it.\n",
        "\n",
        "### How and what to submit\n",
        "\n",
        "A. A **Jupyter Notebook** with the code in all the cells executed and outputs displayed.\n",
        "\n",
        "B. Name your Notebook **COM64102_Assignment_XXXXXX.ipynb** where XXXXXX is your username such as such as abc18de. Example: `COM64102_Assignment_abc18de.ipynb`\n",
        "\n",
        "C. Upload the Jupyter Notebook in B to Blackboard under the submission area before the deadline.\n",
        "\n",
        "D. **NO DATA UPLOAD**: Please do not upload the data files used in this Notebook. We have a copy already.\n",
        "\n",
        "\n",
        "### Assessment Criteria\n",
        "\n",
        "* Being able to compute the posterior distribution in Bayesian logistic regression using a probabilistic program.\n",
        "\n",
        "* Being able to compute several acquisition functions useful for active learning.\n",
        "\n",
        "* Being able to use active learning to speed-up the training process of a digit classifier.\n",
        "\n",
        "\n",
        "### Code quality and use of Python libraries\n",
        "When writing your code, you will find out that there are operations that are repeated at least twice. If your code is unreadable, we may not award marks for that section. Make sure to check the following:\n",
        "\n",
        "* Did you include Python functions to solve the question and avoid repeating code?\n",
        "* Did you comment your code to make it readable to others?\n",
        "\n",
        "### Late submissions\n",
        "\n",
        "We follow Department's guidelines about late submissions, i.e., a deduction of 10% of the mark each 24 hours the work is late after the deadline. NO late submission will be marked one week after the deadline.\n",
        "\n",
        "### Use of unfair means\n",
        "\n",
        "**Any form of unfair means is treated as a serious academic offence and action may be taken under the Discipline Regulations.** Please carefully read [what constitutes Unfair Means](https://documents.manchester.ac.uk/display.aspx?DocID=2870) if not sure. If you still have questions, please ask your Personal tutor or the Lecturers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjSTJn07PvUe"
      },
      "source": [
        "# 1. Probabilistic Programming with PyMC\n",
        "\n",
        "[PyMC](https://www.pymc.io/) is a powerful Python library for **Bayesian statistical modeling** and **probabilistic machine learning**. It provides an intuitive and flexible way to define complex models using a **probabilistic programming framework**.\n",
        "\n",
        "PyMC makes it easy to express statistical models in terms of probability distributions, and it automates the process of computing posterior distributions using state-of-the-art Markov Chain Monte Carlo (MCMC) sampling methods like:\n",
        "- [**No-U-Turn Sampler (NUTS)**](https://jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf), an efficient Hamiltonian Monte Carlo method.\n",
        "- **Metropolis-Hastings** ‚ a traditional and widely-used MCMC approach.\n",
        "\n",
        "Bayesian inference involves calculating the posterior distribution:\n",
        "$$\n",
        "P(\\theta | X) \\propto P(X | \\theta)P(\\theta)\n",
        "$$\n",
        "where:\n",
        "- $P(\\theta)$‚ a prior distribution (our prior belief about the parameters).\n",
        "- $P(X | \\theta)$‚ a likelihood of the data given the parameters.\n",
        "- $P(\\theta | X)$, a posterior distribution (what we want to estimate).\n",
        "\n",
        "Computing this posterior distribution analytically can be difficult or even impossible for complex models. PyMC solves this problem by using efficient numerical sampling techniques, allowing you to approximate the posterior distribution and extract meaningful insights.\n",
        "\n",
        "## How Does PyMC Work?\n",
        "1. **Model Definition**: Define the model using PyMC probabilistic building blocks (e.g., `pm.Normal`, `pm.Bernoulli`).\n",
        "2. **Sampling**: Use `pm.sample()` to draw samples from the posterior distribution.\n",
        "3. **Posterior Analysis**: Analyze the posterior samples to estimate parameters, uncertainties, and credible intervals.\n",
        "\n",
        "PyMC builds on [**Theano**](https://en.wikipedia.org/wiki/Theano_(software)), which allows it to compute gradients and perform symbolic differentiation for more efficient sampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYaNqYbrPvUf"
      },
      "source": [
        "## 1.1 Bayesian inference over the mean of a Gaussian using PyMC\n",
        "\n",
        "In [Lab 1 for this module](https://colab.research.google.com/github/m-caprio/COMP64102-Reasoning-and-Learning-under-Uncertainty-Module/blob/main/New%20Lab%201.ipynb), you computed the posterior distribution over the mean of a Gaussian distribution in closed form using the fact that the Gaussian likelihood and the prior over the mean of the Gaussian likelihood are conjugate. The equation for the mean of the posterior distribution had a closed form.\n",
        "\n",
        "As a warm up example in the use of PyMC, we will do the same example using the probabilistic programming language. Refer to [Lab 1](https://colab.research.google.com/github/m-caprio/COMP64102-Reasoning-and-Learning-under-Uncertainty-Module/blob/main/New%20Lab%201.ipynb) when reading forward.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlpRhM9bPvUf"
      },
      "source": [
        "Besides installing PyMC, we will also install the [ArViz](https://python.arviz.org/en/stable/) package, which is used for exploratory analysis of Bayesian models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "ImVOIHTEPvUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ac398c-1d98-4b19-d67a-6d9d8e30cd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymc in /usr/local/lib/python3.11/dist-packages (5.22.0)\n",
            "Requirement already satisfied: arviz>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pymc) (0.21.0)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.11/dist-packages (from pymc) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from pymc) (3.1.1)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from pymc) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from pymc) (2.2.2)\n",
            "Requirement already satisfied: pytensor<2.31,>=2.30.2 in /usr/local/lib/python3.11/dist-packages (from pymc) (2.30.3)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from pymc) (13.9.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pymc) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl<4.0.0,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from pymc) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pymc) (4.13.2)\n",
            "Requirement already satisfied: setuptools>=60.0.0 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc) (75.2.0)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc) (24.2)\n",
            "Requirement already satisfied: xarray>=2022.6.0 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc) (2025.3.1)\n",
            "Requirement already satisfied: h5netcdf>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc) (1.6.1)\n",
            "Requirement already satisfied: xarray-einstats>=0.3 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc) (0.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->pymc) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->pymc) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->pymc) (2025.2)\n",
            "Requirement already satisfied: filelock>=3.15 in /usr/local/lib/python3.11/dist-packages (from pytensor<2.31,>=2.30.2->pymc) (3.18.0)\n",
            "Requirement already satisfied: etuples in /usr/local/lib/python3.11/dist-packages (from pytensor<2.31,>=2.30.2->pymc) (0.3.9)\n",
            "Requirement already satisfied: logical-unification in /usr/local/lib/python3.11/dist-packages (from pytensor<2.31,>=2.30.2->pymc) (0.4.6)\n",
            "Requirement already satisfied: miniKanren in /usr/local/lib/python3.11/dist-packages (from pytensor<2.31,>=2.30.2->pymc) (1.0.3)\n",
            "Requirement already satisfied: cons in /usr/local/lib/python3.11/dist-packages (from pytensor<2.31,>=2.30.2->pymc) (0.4.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->pymc) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->pymc) (2.19.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from h5netcdf>=1.0.2->arviz>=0.13.0->pymc) (3.13.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->pymc) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->pymc) (1.17.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from logical-unification->pytensor<2.31,>=2.30.2->pymc) (0.12.1)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from logical-unification->pytensor<2.31,>=2.30.2->pymc) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymc\n",
        "import pymc as pm\n",
        "import arviz as az"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGZf0OPJRKM4"
      },
      "source": [
        "The following code uses PyMC to obtain samples from the posterior distribution of the mean of the Gaussian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AEYvCd_4RkYy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "cd9dae3481994b1d98e387cae7eb21d5",
            "921e79d9985342dfa2a269deb03c25db"
          ]
        },
        "outputId": "349f20cb-aa5e-452e-acb3-f2c941cb8236"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd9dae3481994b1d98e387cae7eb21d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posterior mean (mu_p): 3.17\n",
            "Posterior standard deviation (sigma_p): 0.18\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Observed data (assumed to be generated from a Gaussian distribution)\n",
        "data = np.array([3.2, 2.8, 3.6, 3.0, 3.1, 2.9, 3.3, 3.5])\n",
        "\n",
        "# Known standard deviation of the data\n",
        "sigma = 0.5\n",
        "\n",
        "# Define the model in PyMC\n",
        "with pm.Model() as model:\n",
        "    # Prior for mu (mean) - assume Gaussian prior\n",
        "    mu_0 = 3.0  # Prior mean\n",
        "    sigma_0 = 1.0  # Prior standard deviation\n",
        "    mu = pm.Normal('mu', mu=mu_0, sigma=sigma_0) # Prior\n",
        "\n",
        "    # Likelihood for the data - assume Gaussian likelihood\n",
        "    likelihood = pm.Normal('likelihood', mu=mu, sigma=sigma, observed=data) # Likelihood\n",
        "\n",
        "    # Sample from the posterior distribution\n",
        "    trace = pm.sample(2000, return_inferencedata=True)\n",
        "\n",
        "# Extract posterior samples\n",
        "mu_p_samples = trace.posterior['mu'].values.flatten()\n",
        "\n",
        "# Compute posterior mean and standard deviation\n",
        "mu_p = np.mean(mu_p_samples)\n",
        "sigma_p = np.std(mu_p_samples)\n",
        "\n",
        "# Print results\n",
        "print(f\"Posterior mean (mu_p): {mu_p:.2f}\")\n",
        "print(f\"Posterior standard deviation (sigma_p): {sigma_p:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrVPs2LsTKyh"
      },
      "source": [
        "The values for the posterior mean and posterior standard deviation when comparing the exact solution in Lab 1 and the sampling approach using PyMC are the same.\n",
        "\n",
        "**Question 1 (5 marks)**\n",
        "\n",
        "What is the fundamental difference between the approach to compute the mean of the posterior distribution in Lab 1 and the approach to compute the mean using PyMC.\n",
        "\n",
        "*Solution*\n",
        "\n",
        "In lab 1, we used basic probability rules to calculate the mean of a Gaussian distribution using closed-form formulas because the prior and likelihood were both Gaussian (They formed a conjugate pair). This gave us an exact solution.\n",
        "\n",
        "In the above approach using PyMC, instead of solving the math ourselves, we defined the model in code and used PyMC to estimate the posterior by drawing samples using MCMC. This approach gives similar results but works even when an exact formula is not possible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YmKGYopu7UX"
      },
      "source": [
        "We can now plot the prior, likelihood and the posterior pdf's."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bHuuvveMvBTI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "8ce30913-6353-45f1-ea71-2c5dcf309f36"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot prior, likelihood, and posterior\n",
        "x = np.linspace(2, 4, 1000)  # Range of mu values to plot\n",
        "prior = norm.pdf(x, mu_0, sigma_0)  # Prior distribution\n",
        "likelihood = norm.pdf(x, np.mean(data), sigma / np.sqrt(len(data)))  # Likelihood\n",
        "posterior = norm.pdf(x, mu_p, sigma_p)  # Posterior distribution\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, prior, label=\"Prior\", linestyle=\"--\")\n",
        "plt.plot(x, likelihood, label=\"Likelihood\", linestyle=\"-.\")\n",
        "plt.plot(x, posterior, label=\"Posterior\", linestyle=\"-\")\n",
        "plt.title(\"Bayesian Update of Gaussian Mean (PyMC)\")\n",
        "plt.xlabel(\"Mean ($\\mu$)\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmkimtfdxGEf"
      },
      "source": [
        "Two metrics to assess convergence in MCMC are the **effective sample size** (ESS) and the **estimated potential scale reduction** (EPSRC) or **R-hat**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUbtE6o-x057"
      },
      "source": [
        "We can use the [ArViz](https://python.arviz.org/en/stable/) package to compute both quantities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lM4wgfNkyAmt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf5099d-6125-4f35-a78a-0c28b93490eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     mean     sd  hdi_2.5%  hdi_97.5%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
            "mu  3.174  0.178     2.847      3.549      0.004    0.003    1577.0    2552.0   \n",
            "\n",
            "    r_hat  \n",
            "mu    1.0  \n"
          ]
        }
      ],
      "source": [
        "# Posterior summary (for more detailed diagnostics)\n",
        "print(az.summary(trace, var_names=[\"mu\"], hdi_prob=0.95))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iugJGyZo0JNX"
      },
      "source": [
        "**Question 2 (5 marks)**\n",
        "\n",
        "The value of `r_hat` for the mean is equal to 1.0. Explain what `r_hat` computes and whether 1.0 is a good value. Explain why it is or why it is not a good value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn-MMjNi1JRB"
      },
      "source": [
        "*Solution*\n",
        "\n",
        "`r_hat` (Gelman-Rubin statistic) is used to check whether the Markov Chain Monte Carlo (MCMC) sampling has converged. It compares the variance among multiple chains being sampled with the variance within each individual chain. If all the chains have converged to the same posterior (or target) distribution, their variances should be similar.\n",
        "\n",
        "The `r_hat` value we obtained is 1.0, which means the chains are well mixed and have likely converged. This indicates that we are sampling from the same posterior distribution, as their variances are similar. If the value had been significantly greater than 1.0, it would suggest that the chains had not converged, and more sampling or better tuning would be required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaUjD0aM5Jhj"
      },
      "source": [
        "## 1.2 Bayesian logistic regression with PyMC\n",
        "\n",
        "In the previous module in Foundations of Machine Learning, we spent some time on a linear model for classification called **logistic regression**.\n",
        "\n",
        "In a binary classification problem, let $\\mathbf{X}=[\\mathbf{x}_1 \\cdots \\mathbf{x}_N]^\\top$ and and $\\mathbf{y} =[y_1\\cdots y_N]^{\\top}$, where $\\mathbf{X}$ is the design matrix and each element in $\\mathbf{y}$, say $y_n$ indicates to which class the corresponding input vector, $\\mathbf{x}_n$, belongs to.\n",
        "\n",
        "Assumming IID observations, the likelihood for the dataset is given as\n",
        "\\begin{align*}\n",
        "p(\\mathbf{y}|\\mathbf{w},\\mathbf{X}) = \\prod_{n=1}^Np(y_n|\\mathbf{w},\\mathbf{x}_n)\n",
        "  =\\prod_{n=1}^N\\textrm{Ber}(y_n|\\sigma(\\mathbf{w}^{\\top}\\mathbf{x}_n)),\n",
        "\\end{align*}\n",
        "where $\\textrm{Ber}(y_n|\\mu)$ refers to the Bernoulli distribution with parameter $\\mu$, and $\\sigma(a)$ is the sigmoid function defined as $\\sigma(a)=\\frac{1}{1+ \\exp(-a)}$.\n",
        "\n",
        "The maximum-likelihood estimator for $\\mathbf{w}$ can be obtained by minimising the negative log-likelihood (or the cross-entropy function) given as\n",
        "\n",
        "\\begin{align*}\n",
        "NLL(\\mathbf{w}) & = - \\log p(\\mathbf{y}|\\mathbf{w},\\mathbf{X}) \\\\\n",
        "& = - \\sum_{n=1}^N\\{y_n\\log[\\sigma(\\mathbf{w}^{\\top}\\mathbf{x}_n)] + (1-y_n)\\log[1 - \\sigma(\\mathbf{w}^{\\top}\\mathbf{x}_n)] \\}.\n",
        "\\end{align*}\n",
        "\n",
        "In *Bayesian logistic regression*, we put a prior over the weights $\\mathbf{w}$. We then compute the posterior distribution\n",
        "\\begin{align*}\n",
        "p(\\mathbf{w}|\\mathbf{X}, \\mathbf{y}) \\propto p(\\mathbf{y}|\\mathbf{w}, \\mathbf{X})p(\\mathbf{w}).\n",
        "\\end{align*}\n",
        "For predicting the class of a text point, $\\mathbf{x}_*$, we need to compute the predictive distribution,\n",
        "\\begin{align}\n",
        "p(y_*|\\mathbf{x}_*)=\\int \\sigma(\\mathbf{w}^{\\top}\\mathbf{x}_*)p(\\mathbf{w}|\\mathbf{X}, \\mathbf{y})d\\mathbf{w}.\n",
        "\\end{align}\n",
        "\n",
        "If we approximate the posterior distribution $p(\\mathbf{w}|\\mathbf{X}, \\mathbf{y})$ with a Gaussian posterior distribution,\n",
        "\\begin{align*}\n",
        "p(\\mathbf{w}|\\mathbf{X}, \\mathbf{y}) ≈ q(\\mathbf{w}|\\mathbf{X}, \\mathbf{y}) = N(\\mathbf{w}|𝛍_{\\text{post}}, 𝚺_{\\text{post}}),\n",
        "\\end{align*}\n",
        "it can be shown the predictive distribution can also be approximated as\n",
        "\\begin{align*}\n",
        "p(y_*=1|\\mathbf{x}_*) = \\sigma(\\kappa (\\sigma^2_a)\\mu_a),\n",
        "\\end{align*}\n",
        "where\n",
        "\\begin{align*}\n",
        "\\mu_a &= 𝛍_{\\text{post}}^\\top\\mathbf{x}_*,\\\\\n",
        "\\sigma_a^2 &= \\mathbf{x}^\\top_*𝚺_{\\text{post}}\\mathbf{x}_*,\\\\\n",
        "\\kappa(\\sigma^2) &= \\frac{1}{(1+\\pi \\sigma^2/8)^{\\frac{1}{2}}}\n",
        "\\end{align*}\n",
        "\n",
        "\n",
        "### Bayesian logistic regression for the Iris dataset\n",
        "\n",
        "To illustrate how Bayesian logistic regression works, we will use a very well known dataset, the [Iris dataset](https://archive.ics.uci.edu/dataset/53/iris). The dataset has three classes and four input features. We will only use two classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukNbfo9zvDNN"
      },
      "source": [
        "Let us load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SdETdAXgvFTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0a4136-99a5-42e3-f195-e020f68239b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "iris = fetch_ucirepo(id=53)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X3 = iris.data.features\n",
        "y3 = iris.data.targets\n",
        "# Drop the last class and the last two columns\n",
        "Xp = X3.drop(X3.index[100:150])\n",
        "yp = y3.drop(y3.index[100:150])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt3Ncv8jynbB"
      },
      "source": [
        "We now have a reduced dataset that we will split into training and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EhZDzlvIvdAe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "# We add a vector of ones to the input space in X\n",
        "X = Xp.to_numpy()\n",
        "# Add a column of ones to X\n",
        "y = np.vstack((np.zeros((50, 1)), np.ones((50, 1))))\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=int(1e3))\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2AWsxxNzs0y"
      },
      "source": [
        "**Question 3 (10 marks)**\n",
        "\n",
        "Let us define the following prior distribution for $\\mathbf{w}$, $p(\\mathbf{w})= N(\\mathbf{w}|\\mathbf{0}_4, 0.001\\times \\mathbf{I}_4)$, where $\\mathbf{0}_4 = [0, 0, 0, 0]^\\top$ and $\\mathbf{I}_4$ is the identity matrix of dimension four since there are four input features.\n",
        "\n",
        "Using the training data `X_train` and `y_train`, compute an approximate posterior Gaussian distribution using PyMC for a Bayesian logistic regression model. Use 2000 samples for the sampler and report the mean and the covariance matrix for the approximate Gaussian using the last 1000 samples of one of the chains (**7 marks**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL67G-rT11O6"
      },
      "source": [
        "*Solution*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H23KT6fe1y21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "0586938686004dd4ac9f6778d7135c78",
            "9639fef5045a438eace08079546af5b3"
          ]
        },
        "outputId": "c35b8d2a-8c12-4ccf-b1e4-422922045d0d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0586938686004dd4ac9f6778d7135c78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posterior mean of weights:\n",
            " [ 0.01881136 -0.02001957  0.02746464  0.02616561]\n",
            "\n",
            "Posterior covariance matrix:\n",
            " [[ 9.23034760e-04 -5.25743912e-05  2.62873970e-05 -1.22066299e-05]\n",
            " [-5.25743912e-05  9.55794174e-04  2.75607197e-05 -5.17392949e-06]\n",
            " [ 2.62873970e-05  2.75607197e-05  9.97345822e-04 -7.70207045e-05]\n",
            " [-1.22066299e-05 -5.17392949e-06 -7.70207045e-05  9.97391860e-04]]\n"
          ]
        }
      ],
      "source": [
        "y_train_flat = y_train.flatten()\n",
        "mean_prior = np.zeros(4)\n",
        "cov_prior = 0.001 * np.eye(4)\n",
        "\n",
        "with pm.Model() as logistic_model:\n",
        "    w = pm.MvNormal(\"w\", mu=mean_prior, cov=cov_prior)\n",
        "\n",
        "    logit = pm.math.dot(X_train, w)\n",
        "\n",
        "    y_obs = pm.Bernoulli(\"y_obs\", logit_p=logit, observed=y_train_flat)\n",
        "\n",
        "    trace = pm.sample(2000, chains=2, return_inferencedata=True, target_accept=0.9)\n",
        "\n",
        "w_posterior_samples = trace.posterior[\"w\"].sel(chain=0).isel(draw=slice(-1000, None)).values\n",
        "\n",
        "w_posterior_mean = np.mean(w_posterior_samples, axis=0)\n",
        "\n",
        "w_posterior_cov = np.cov(w_posterior_samples, rowvar=False)\n",
        "\n",
        "print(\"Posterior mean of weights:\\n\", w_posterior_mean)\n",
        "print(\"\\nPosterior covariance matrix:\\n\", w_posterior_cov)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-NGzSdwm1NP"
      },
      "source": [
        "Compute the accuracy of the linear classifier over the test set using the approximated distribution $p(y_*=1|\\mathbf{x}_*) = \\sigma(\\kappa (\\sigma^2_a)\\mu_a)$, as explained above (**3 marks**)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Solution*"
      ],
      "metadata": {
        "id": "IiTVWabFXZgm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RWzhzUPRkwY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01fdf75a-0305-4266-d305-4a8518df92c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "from scipy.special import expit\n",
        "\n",
        "mu_a = X_test @ w_posterior_mean\n",
        "\n",
        "temp = X_test @ w_posterior_cov\n",
        "\n",
        "sigma_a2 = np.sum(temp * X_test, axis=1)\n",
        "\n",
        "k_sigma_a2 = 1.0 / np.sqrt(1.0 + (np.pi * sigma_a2) / 8.0)\n",
        "\n",
        "pred_prob = expit(k_sigma_a2 * mu_a)\n",
        "\n",
        "y_pred = (pred_prob >= 0.5).astype(int).flatten()\n",
        "\n",
        "accuracy = np.mean(y_pred == y_test.flatten())\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWKwKL2QVO4Z"
      },
      "source": [
        "# 2. Active Learning -- Using data selection via uncertainty to keep models fresh\n",
        "\n",
        "We can use\n",
        "uncertainties to figure out whether data should be part of the training data\n",
        "or not. We can expand on this idea in the context of an area of\n",
        "machine learning called **active learning**. The promise of active\n",
        "learning is that a model can learn more eﬀectively on less data if we\n",
        "have a way to control the type of data it is trained on. Active learning is a way to\n",
        "guide the learning process and data a model is trained on by\n",
        "**providing acquisition functions** that can acquire data from a pool of data that is\n",
        "not part of the training data. By iteratively selecting the right data\n",
        "from the pool, we can train a model that performs better than if we\n",
        "had chosen the data from the pool at random.\n",
        "\n",
        "The active learning approach can be described with the following iterative procedure\n",
        "```\n",
        "A model is initially trained using a few samples per class\n",
        "for iter until a fixed number of iterations:\n",
        "  compute an acquisition function over the data in the pool\n",
        "  based on the acquisition function select a sample to include in the  \n",
        "     training data\n",
        "  train the model again using the augmented training data\n",
        "```\n",
        "\n",
        "In this part of the coursework, we will use results from a fundamental\n",
        "active learning paper: [Deep Bayesian Active Learning with Image Data\n",
        "(2017)](https://arxiv.org/abs/1703.02910). We will use the MNIST dataset and train a model on more\n",
        "and more data, where we select the data points to add to our\n",
        "training set via an uncertainty method. In this case, we will use **epistemic uncertainty** to select the most informative data points.\n",
        "Images with high epistemic uncertainty will be added to the traininig dataset in a sequential manner. The epistemic uncertainty can be computed using different methods. You will use **Monte Carlo dropout** and will compare the performance of using epistemic uncertainty to introduce new points in the training data against including new training points just but randomly selecting from a pool of available data.\n",
        "\n",
        "**IMPORTANT** To reduce the amount of code appearing in the notebook, we have created a set of python modules that include auxiliary functions. You need to make sure when running the notebook that your Google Drive is mounted and the auxiliar Python files can be accessed from the Notebook. On how to allow your Notebook to find the .py files in your Google Drive, see instructions in this [link](https://nimbusintelligence.com/2023/03/import-python-scripts-in-google-colab/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "-cg9BNEcma5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0769af14-0f40-4245-f192-501054206f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "# The path here can be different, depending on where you have uploaded the auxiliary Python files config.py, main.py, utils.py, model.py, visualise.py, data.py\n",
        "sys.path.insert(0,'/content/drive/My Drive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aogBdN1kXaWI"
      },
      "source": [
        "We start by importing a set of modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2ZECq2uAVUbw"
      },
      "outputs": [],
      "source": [
        "import dataclasses\n",
        "from typing import Optional, Tuple, Union, Callable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from pathlib import Path\n",
        "import gc\n",
        "import uuid\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ppd49QmyX3Ns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89bbf32-eebf-462b-da05-4b57a513ef42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting laplace-torch\n",
            "  Downloading laplace_torch-0.2.2.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting asdfghjkl==0.1a4 (from laplace-torch)\n",
            "  Downloading asdfghjkl-0.1a4-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting backpack-for-pytorch (from laplace-torch)\n",
            "  Downloading backpack_for_pytorch-1.7.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting curvlinops-for-pytorch>=2.0 (from laplace-torch)\n",
            "  Downloading curvlinops_for_pytorch-2.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from laplace-torch) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from laplace-torch) (3.4.0)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from laplace-torch) (2.6.0+cu124)\n",
            "Collecting torchmetrics (from laplace-torch)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torchvision>=0.15 in /usr/local/lib/python3.11/dist-packages (from laplace-torch) (0.21.0+cu124)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from curvlinops-for-pytorch>=2.0->laplace-torch) (1.15.2)\n",
            "Collecting numpy (from laplace-torch)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.61.0 in /usr/local/lib/python3.11/dist-packages (from curvlinops-for-pytorch>=2.0->laplace-torch) (4.67.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from curvlinops-for-pytorch>=2.0->laplace-torch) (0.8.1)\n",
            "Collecting einconv (from curvlinops-for-pytorch>=2.0->laplace-torch)\n",
            "  Downloading einconv-0.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting unfoldNd<1.0.0,>=0.2.0 (from backpack-for-pytorch->laplace-torch)\n",
            "  Downloading unfoldNd-0.2.3-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->laplace-torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->laplace-torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->laplace-torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->laplace-torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->laplace-torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->laplace-torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->laplace-torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->laplace-torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->laplace-torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->laplace-torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->laplace-torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.15->laplace-torch) (11.2.1)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics->laplace-torch) (24.2)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->laplace-torch)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics->laplace-torch) (75.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->laplace-torch) (3.0.2)\n",
            "Downloading laplace_torch-0.2.2.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asdfghjkl-0.1a4-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curvlinops_for_pytorch-2.0.1-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backpack_for_pytorch-1.7.1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.6/196.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading unfoldNd-0.2.3-py3-none-any.whl (16 kB)\n",
            "Downloading einconv-0.1.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, unfoldNd, torchmetrics, einconv, asdfghjkl, backpack-for-pytorch, curvlinops-for-pytorch, laplace-torch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asdfghjkl-0.1a4 backpack-for-pytorch-1.7.1 curvlinops-for-pytorch-2.0.1 einconv-0.1.0 laplace-torch-0.2.2.2 lightning-utilities-0.14.3 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.7.1 unfoldNd-0.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install laplace-torch\n",
        "from laplace import Laplace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql9vxE4EZFq5"
      },
      "source": [
        "## 2.1 Preparing the dataset\n",
        "\n",
        "We work with the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ef2Rt5ZEX3lG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "outputId": "2f0f2c3c-464b-4c94-e21d-3b1a5b11385e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 40.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.28MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.4MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.00MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv4AAAMWCAYAAACJBYLiAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARidJREFUeJzt3WmYVeWZNuy7mAeRRBFQQOQNClHUKGKMiSigOCNpbOMcTVqPBKPRTA4Y5xFji9LBMcIbsDW+MUZNgnFAESWDI92COBBFRCFOoCAqUPv74ScBh2dVsWvYVc95Hgc/3NeutZ6qYt9etdj1rKpSqVQKAACgWWvR2AsAAADqn+IPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOLfRJxzzjlRVVW1Xh87adKkqKqqipdeeqluFwU0GjMBWJuZQE0o/o3g4xfYx3/atWsXm222Wey9995x1VVXxbvvvlvva5gwYUJMmjSpTo41b968OPzww6Nr167Rvn372HLLLWPMmDF1cmzIQXOaCRdeeGGMGDEiunXrFlVVVXHOOeeUfUzITXOaCS+88EIcfPDB8cUvfjE6dOgQ3/jGN+KBBx4of4Gsl6pSqVRq7EXkZtKkSXHsscfGeeedF3369ImVK1fGokWL4sEHH4x77703Nt9887jzzjtju+22W/Mxq1atilWrVkW7du1qfb7Vq1fHypUro23btmuuBgwYMCC6dOkSDz74YFmfy1NPPRV77LFH9OjRI44++ujYeOON4+WXX44FCxbExIkTyzo25KI5zYSqqqro3r17bL/99vHnP/85zj77bOUfaqm5zIQFCxbEjjvuGC1btoyTTjopOnbsGBMnTozZs2fH/fffH4MHD17vY7N+WjX2AnK27777xk477bTmv08//fSYNm1aHHDAATFixIh45plnon379hER0apVq2jVav2+XS1btoyWLVvWyZrXVl1dHUcddVT0798/HnjggTVrBdZPU58JEREvvvhibLHFFvHGG2/EJptsUi/ngFw09ZlwySWXxJIlS+Lpp5+Ofv36RUTEcccdF/37949TTjklHn/88To/J2ne6lNhhg4dGj//+c9j/vz5MWXKlDWPf9Z791asWBEnnXRSdOnSJTp16hQjRoyIhQsXfuqf1z/53r0tttgiZs+eHdOnT1/zz4h77LHHmufPmzcv5s2bV7jWe+65J55++uk4++yzo3379vHee+/F6tWry/r8gXU1pZnw8bGA+tOUZsKMGTNihx12WFP6IyI6dOgQI0aMiCeeeCKef/759fsisN4U/wp01FFHRcRHxTrlmGOOifHjx8d+++0Xl156abRv3z7233//wuOPGzcuevbsGf3794/JkyfH5MmT13lP/rBhw2LYsGGFx7nvvvsiIqJt27ax0047RceOHaNDhw5x6KGHxltvvVX48UDNNJWZADSMpjITPvjgg898N0CHDh0iIlzxbwTe6lOBevbsGZ07d07+NP3EE0/ErbfeGieffHJcccUVERExevToOPbYY2PWrFnJ448cOTLOPPPM6NKlSxx55JHrvc6Pf1I/5JBDYp999onTTz89Zs2aFRdffHEsWLAgHn744fXeYQD4l6YyE4CG0VRmQr9+/WLGjBnx7rvvRqdOndY8/vDDD0dExMKFC9f72KwfV/wr1AYbbJD8rf277747Ij56Ea/txBNPLPvcL730Uo229Fq2bFlERAwaNCimTJkSo0aNivPOOy/OP//8mDlzZtx///1lrwX4SFOYCUDDaQoz4fvf/34sWbIkvvWtb8WTTz4Zzz33XJx88snx2GOPRcRHb0WiYSn+FWrZsmXr/HT8SfPnz48WLVpEnz591nm8b9++9b20NT7+57vDDjtsnccPP/zwiIiYOXNmg60FmrumMBOAhtMUZsK+++4b48ePj4ceeih23HHH6NevX/zxj3+MCy+8MCI++uGFhqX4V6BXXnklli5dWvH/w95ss80iIqJbt27rPN61a9eIiHj77bcbfE3QHDWVmQA0jKY0E37wgx/E4sWLY+bMmfHYY4/F3Llzo3PnzhERsdVWWzXy6vKj+FegyZMnR0TE3nvv/bnP6d27d1RXV8eLL764zuMvvPBCjc5RF++9HzhwYER8+j16r776akSErfygjjSVmQA0jKY2Ezp27Bhf+9rXYuDAgdGyZcu47777on379vH1r3+9zs5BzSj+FWbatGlx/vnnR58+feKII4743Od9/GKfMGHCOo+PHz++Rufp2LFjLFmy5DOzmm7TddBBB0Xbtm1j4sSJUV1dvebxG264ISIi9tprrxqtBfh8TWkmAPWvqc+EmTNnxu9+97v47ne/u+bKPw3Hrj6NaOrUqTF37txYtWpVLF68OKZNmxb33ntv9O7dO+68887k3fcGDhwYo0aNinHjxsWbb74Zu+yyS0yfPj2ee+65iCj+SX3gwIFx9dVXxwUXXBB9+/aNrl27xtChQyMi1mzRVfSLO927d48xY8bEWWedFfvss0+MHDkyZs2aFddff30cdthhMWjQoFp8NYCmPhMiProSOX/+/HjvvfciIuKhhx6KCy64ICI+2oKwd+/ehccAPtLUZ8L8+fPjkEMOiREjRkT37t1j9uzZcc0118R2220XF110US2+EtSZEg1u4sSJpYhY86dNmzal7t27l/baa6/SlVdeWXrnnXc+9TFnn3126ZPfruXLl5dOOOGE0kYbbVTaYIMNSiNHjiw9++yzpYgoXXLJJZ8634svvrjmsUWLFpX233//UqdOnUoRUdp9993XZL179y717t27Rp9LdXV1afz48aWtttqq1Lp161KvXr1KZ555ZunDDz+s1dcEctacZsLuu+++zuey9p8HHnigNl8WyFZzmQlvvfVW6aCDDip179691KZNm1KfPn1Kp5566meun4ZRVSqVSg30MwYN4KmnnooddtghpkyZkvwnQCAPZgKwNjMhb97j34R91v6348aNixYtWsTgwYMbYUVAYzITgLWZCXyS9/g3YWPHjo3HH388hgwZEq1atYqpU6fG1KlT4/jjj49evXo19vKABmYmAGszE/gkb/Vpwu69994499xzY86cObFs2bLYfPPN46ijjooxY8ZEq1Z+poPcmAnA2swEPknxBwCADHiPPwAAZEDxBwCADCj+AACQgRr/ZkfRHd6A+lVpv45jJkDjqrSZEGEuQGMrmguu+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJCBVo29ACpHt27dkvmtt96azO+8885kfvnll9d6TQAA1A1X/AEAIAOKPwAAZEDxBwCADCj+AACQAcUfAAAyoPgDAEAGFH8AAMiAffwz0aNHj8Ln3H777cl8p512Sua77bZbMm/Tpk0yv/jii5M58C/du3dP5kX33Wjfvn3hOf7t3/4tmS9YsKDwGABUDlf8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIB9/JuJon36b7vttsJjFO3TX2TWrFnJ/IYbbijr+MC//N//+3+TedF9NWqiaCbYxx+gaXHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAzYx7+Z2GOPPZL5zjvvXPY5Xn/99WR+wAEHlPXxQM1tv/32jb0EAJoYV/wBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgH38m4mjjjqq3s9xww03JPOFCxfW+xqAjxTdF6Nbt25ln6Nr165lHwOouS222CKZ33HHHcl8u+22S+bV1dW1XVKt/eEPf0jmY8eOTeZPPPFEMl+xYkWt18S/uOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABqpKpVKpRk+sqqrvtZCw4YYbJvO5c+cm8+7duxee44UXXkjm++23X1kfT3lq+FJtMGZC4xo2bFgyv++++8o+x/vvv5/M27dvX/Y5WH+VNhMizIUOHTok8xNOOCGZ77PPPsl88ODBybxFi/T13IbYx79cX/7yl8v6+I022iiZ//3vfy/r+JWuaC644g8AABlQ/AEAIAOKPwAAZEDxBwCADCj+AACQAcUfAAAyoPgDAEAGWjX2AqiZ119/PZm3bt267HOMHj06mdunH4DmbM8990zmRfvwt2nTJpkPHz681mvKzYQJE5L5BhtskMw7duyYzP/xj38k829+85vJvKlzxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAM2Me/Quy6667JvEWL8n5Ge/nllwufs2DBgrLOAQCN6de//nUy33vvvZN527Ztk3nRHvH1bf78+cn8gw8+SOZTpkxJ5tdee23hGvr27ZvMH3nkkcJjpAwZMqSsjy+y9dZb1+vxK50r/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGTAPv4NpHXr1sn8pz/9aTJv2bJlWee/5ZZbCp/z7LPPlnUOoOE8/PDDybzoNX/ooYfW5XKgQWy33XbJvGiP9o022qgul/Mp77//fjL/7//+77KOP3bs2GQ+b968so5fE0uXLq33c1B/XPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA/bxbyBnnHFGMj/ooIPKOv7UqVOT+bnnnlvW8SMi2rVrl8wHDx6czIcNG5bMhw8fnswPPPDAZP7KK68kc2hOPvjgg2S+YsWKBloJ1J0bbrghmQ8YMCCZb7/99nW5nFo788wzk/mVV17ZQCupP4sWLUrmkyZNSubHHHNM3S2GWnPFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAzYx7+BbLrppvV6/NmzZyfzmuzpXbQP/wUXXJDMv/GNbxSeoxyjR49O5kX3SgCgsh177LHJvLq6ul7Pf9tttyXzon36X3755bpcTkVavnx5Mr/44ouTedeuXZP5fvvtV+s1UXOu+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJAB+/g3EcuWLUvm11xzTTIfMmRI4Tn++7//O5l37949mZdKpcJzlGPLLbes1+MD0LhmzJiRzL/+9a/X6/k7d+6czLfeeutk3rdv32Q+a9asZD5o0KBkXuStt95K5osWLUrmRZ9fRESPHj2S+VVXXVV4DBqPK/4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMuIFXHenSpUsy33XXXcs6/q9+9atkfvHFFyfzf//3fy/r/BH1f4OuInfeeWejnh+A+jVmzJhk/uCDD9br+ffcc8+y8hUrViTzP//5z8l85MiRybzIa6+9lsyff/75ZD548OCyzk/lc8UfAAAyoPgDAEAGFH8AAMiA4g8AABlQ/AEAIAOKPwAAZEDxBwCADNjHv46MGjUqmQ8YMKCs47/66qvJ/Ic//GFZx28KHnnkkcZeAmSlqqoqmX/hC19I5kuWLKm7xZCF//3f/03mV199dTL//ve/X5fLqbX27dsn83L36S/So0ePZL7pppuWfY758+cn8yOPPLKs4xfNlbvuuqus4+fOFX8AAMiA4g8AABlQ/AEAIAOKPwAAZEDxBwCADCj+AACQAcUfAAAyYB//OjJ8+PB6Pf75559fr8evBLNnz07m77zzTgOtBIiIaNu2bTL/xS9+kcz/4z/+oy6XQwaK5vxJJ51UVt67d+9kPnny5GRe37bYYotk/uabbybzZcuWJfNSqVTbJX3KAQcckMzL/X/1kCFDknmLFq5Zl8NXDwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAzYx7+JePbZZ5P5tttuW+9rqKqqSuZF+wPPnTs3me+zzz7J/I033kjmwL+cc845yfzII48sPEbr1q3raDVQGebPn5/MBw8e3EAr+Wz77rtvMp8zZ04yL/r8moJf/vKXyby6urqBVtI8ueIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABuzj30Q88sgjybwh9vEv2qe/KL/88suT+cKFC2u9JuCzvfzyy8m86PUKNLypU6c29hJo5lzxBwCADCj+AACQAcUfAAAyoPgDAEAGFH8AAMiA4g8AABlQ/AEAIAP28a8jixcvrtfjf+9736vX49fEm2++mcyPPvroZG5/YmheunXrlsw7d+6czJcuXVqXywGggCv+AACQAcUfAAAyoPgDAEAGFH8AAMiA4g8AABlQ/AEAIAOKPwAAZKCqVCqVavTEqqr6XkuTtsUWWyTzOXPmJPN27drV4Wo+beXKlYXPKVrjxRdfnMxvvfXWWq2J2qnhS7XBmAlN2wcffFD4nDZt2pR1jqFDhybzBx54oKzj567SZkKEuUD5irrIlltuWa/nb926db0ev74VzQVX/AEAIAOKPwAAZEDxBwCADCj+AACQAcUfAAAyoPgDAEAGFH8AAMiAffwbyPDhw5P5T3/602Q+bNiwZP7UU08l86I9+CMi/t//+3+Fz6HxVNqe3WZC09YQ+/j/4x//SOZf+tKXyjp+7iptJkSYC5TPPv7lsY8/AACg+AMAQA4UfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMtGrsBeTinnvuKSsHqEv/9V//VficH/3oR2Wd48Ybbyzr4wGoW674AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkIGqUqlUqtETq6rqey1AQg1fqg3GTIDGVWkzIcJcoHxz5sxJ5ltuuWVZx58xY0YyHzp0aFnHb2xFc8EVfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADLQqrEXAAAAERHLly9P5qeddlpZx7/55pvL+vimzhV/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMlBVKpVKNXpiVVV9rwVIqOFLtcGYCdC4Km0mRJgLlG/AgAHJ/Omnn26glTRNRXPBFX8AAMiA4g8AABlQ/AEAIAOKPwAAZEDxBwCADCj+AACQAcUfAAAyYB9/aCIqbc9uMwEaV6XNhAhzARqbffwBAADFHwAAcqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGSgxvv4AwAATZcr/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADin8Tcc4550RVVdV6feykSZOiqqoqXnrppbpdFNBozARgbWYCNaH4N4KPX2Af/2nXrl1sttlmsffee8dVV10V7777br2vYcKECTFp0qSyj/PCCy/EwQcfHF/84hejQ4cO8Y1vfCMeeOCB8hcIGWlOM+G1116L448/Pvr06RPt27ePL33pS/GjH/0o3nzzzfIXCZloTjNhbTfddFNUVVXFBhtsUKfHpeaqSqVSqbEXkZtJkybFscceG+edd1706dMnVq5cGYsWLYoHH3ww7r333th8883jzjvvjO22227Nx6xatSpWrVoV7dq1q/X5Vq9eHStXroy2bduuuRowYMCA6NKlSzz44IPr/XksWLAgdtxxx2jZsmWcdNJJ0bFjx5g4cWLMnj077r///hg8ePB6Hxty0lxmwrJly2LAgAGxfPnyGD16dPTq1StmzZoV1157bWyzzTbx+OOPR4sWrjdBkeYyE9a2bNmy6NevXyxdunTNf9PwWjX2AnK27777xk477bTmv08//fSYNm1aHHDAATFixIh45plnon379hER0apVq2jVav2+XS1btoyWLVvWyZrXdskll8SSJUvi6aefjn79+kVExHHHHRf9+/ePU045JR5//PE6Pyc0Z019Jtx5550xf/78+MMf/hD777//msc32mijOO+882LWrFmxww471Pl5oblq6jNhbRdccEF06tQphgwZEr///e/r9Vx8PpdeKszQoUPj5z//ecyfPz+mTJmy5vHPeu/eihUr4qSTToouXbpEp06dYsSIEbFw4cKoqqqKc845Z83zPvnevS222CJmz54d06dPX/PPiHvsscea58+bNy/mzZtXuNYZM2bEDjvssKb0R0R06NAhRowYEU888UQ8//zz6/dFANZoSjPhnXfeiYiIbt26rfP4pptuGhGxpqAA668pzYSPPf/883HFFVfEf/7nf673DyfUDcW/Ah111FEREXHPPfckn3fMMcfE+PHjY7/99otLL7002rdvv85Vts8zbty46NmzZ/Tv3z8mT54ckydPjjFjxqzJhw0bFsOGDSs8zgcffPCZ/yPv0KFDRIQr/lBHmspMGDx4cLRo0SJ++MMfxl//+td45ZVX4k9/+lNceOGFMXLkyOjfv3/hMYBiTWUmfOzkk0+OIUOGxH777Vfjj6F++LGrAvXs2TM6d+6c/Gn6iSeeiFtvvTVOPvnkuOKKKyIiYvTo0XHsscfGrFmzkscfOXJknHnmmdGlS5c48sgj13ud/fr1ixkzZsS7774bnTp1WvP4ww8/HBERCxcuXO9jA//SVGbC1ltvHdddd1385Cc/ia997WtrHv/2t78dN9xww3ofF1hXU5kJERF//OMf45577ik8Jw3DFf8KtcEGGyR/a//uu++OiI9exGs78cQTyz73Sy+9VKMtvb7//e/HkiVL4lvf+lY8+eST8dxzz8XJJ58cjz32WER89E+MQN1oCjMhIqJHjx6x8847x7hx4+L222+PH/3oR3HTTTfFaaedVvY6gH9pCjPhww8/jFNOOSW+973vxdZbb132eSmfK/4VatmyZdG1a9fPzefPnx8tWrSIPn36rPN4375963tpa+y7774xfvz4OO2002LHHXdcc/4LL7wwfvazn9muC+pQU5gJjzzySBxwwAHx17/+dc0vJI4cOTI23HDDOPfcc+M73/mO//lDHWkKM+GKK66IN954I84999wGOydprvhXoFdeeSWWLl3aoC/O9fWDH/wgFi9eHDNnzozHHnss5s6dG507d46IiK222qqRVwfNQ1OZCddee21069ZtnV1IIiJGjBgRpVIpZs6c2Ugrg+alKcyEpUuXxgUXXBDHHXdcvPPOO2v+lWDZsmVRKpXipZdein/+85+NvczsKP4VaPLkyRERsffee3/uc3r37h3V1dXx4osvrvP4Cy+8UKNzrO/d/T5Lx44d42tf+1oMHDgwWrZsGffdd1+0b98+vv71r9fZOSBnTWUmLF68OFavXv2px1euXBkRH+0zDpSvKcyEt99+O5YtWxZjx46NPn36rPlz2223xXvvvRd9+vSJ448/vqxzUHuKf4WZNm1anH/++dGnT5844ogjPvd5H7/YJ0yYsM7j48ePr9F5OnbsGEuWLPnMrLbbdK1t5syZ8bvf/S6++93vrrnyD6y/pjQTttpqq1i8ePGnbvhz8803R0TYwx/qQFOZCV27do3bb7/9U3+GDBkS7dq1i9tvvz1OP/30Gq2FuuM9/o1o6tSpMXfu3Fi1alUsXrw4pk2bFvfee2/07t077rzzzuTd9wYOHBijRo2KcePGxZtvvhm77LJLTJ8+PZ577rmIKP5JfeDAgXH11VfHBRdcEH379o2uXbvG0KFDIyLWbNFV9Is78+fPj0MOOSRGjBgR3bt3j9mzZ8c111wT2223XVx00UW1+EoAEU1/JvzgBz+IiRMnxoEHHhgnnnhi9O7dO6ZPnx4333xz7LXXXvHVr361Fl8NoCnPhA4dOsTIkSM/9fjvf//7+Pvf//6ZGfVP8W9EZ511VkREtGnTJjbaaKPYdtttY9y4cXHssceusz3m5/n1r38d3bt3j5tvvjluv/322HPPPeM3v/lN9OvXr/CW3WeddVbMnz8/xo4dG++++27svvvua17QNbXhhhvGpptuGv/1X/8Vb731VvTo0SNOOumkGDNmTI3WD6yrqc+Efv36xeOPPx5nnnlmTJkyJRYtWhSbbbZZ/OQnP/HLfbAemvpMoPJUlUqlUmMvgrrz1FNPxQ477BBTpkxJ/hMgkAczAVibmZA37/Fvwj5rn/xx48ZFixYtYvDgwY2wIqAxmQnA2swEPslbfZqwsWPHxuOPPx5DhgyJVq1axdSpU2Pq1Klx/PHHR69evRp7eUADMxOAtZkJfJK3+jRh9957b5x77rkxZ86cWLZsWWy++eZx1FFHxZgxY6JVKz/TQW7MBGBtZgKfpPgDAEAGvMcfAAAyoPgDAEAGFH8AAMhAjX+zo+gOb0D9qrRfxzEToHFV2kyIMBegsRXNBVf8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAZaNfYCAPi0TTfdNJkPGjQomY8ZMyaZ77TTTrVe0ydddNFFyfyWW25J5s8++2wyX7VqVa3XtLZ27dol8+nTpyfzAQMGJPOvf/3ryfypp55K5gANzRV/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMmAf/wZyzDHHJPPDDz88me+5555lnb+qqqrwOaVSqaxz3HTTTcn8gw8+SOaPPPJIMp8zZ04y/9vf/pbMoSEdfPDByXz06NHJfMstt0zmRfv8F5k5c2bhcxYuXJjMzzjjjGR++umnJ/Nvf/vbybxophT58Y9/nMwHDhyYzFesWFHW+eGTiubC2WefnczPOuusZH777bfXek25KZpLw4cPT+YXXHBBMr///vtrvaaG5Io/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGbCPfw194QtfSOZ/+ctfkvkWW2yRzNu0aZPMy91jvybKPUfRvQiKfOc730nmTzzxRDIvulfC008/Xdslwecq2k/7tNNOS+ZFr/nly5cn86KZc9FFFyXzadOmJfOI4ntvdOvWLZnvtttuybzoNVu0j/8JJ5yQzIvuM1DkwQcfTObPPPNMWccnPwceeGAy33rrrZP5kCFDkrl9/CN23XXXZH7mmWcm83bt2iXzwYMHJ3P7+AMAAI1O8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZsI///69nz57J/Mknn0zmG2+8cTJviH34m7sddtghmV9//fXJfPfdd0/mH374Ya3XRPPVt2/fZP7jH/84mRft03/55Zcn8+uuuy6Zz5s3L5k3hGuuuSaZF+3jv+GGGybz3/zmN8l8+PDhybxoP+6ZM2cm81NPPTWZF93ngPxstNFGyXynnXZK5qtXr07m22yzTa3X1NwUva6LXrdFH9/cueIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABrLZx79Tp07JfMaMGcm8aG/eIm+++WYyf/3115P5Y489lsyffvrpWq/pk/bbb79k/qc//ansc6QcfPDBybxo/+OOHTsm85YtW9Z6TfB5/ud//ieZf+1rX0vm//jHP5J5JezTX98GDhxYVl6k6Gt42GGHJfNXXnmlrPPT/HTu3DmZjxs3Lpn3798/mf/tb39L5sOGDUvmOfje976XzA844IB6Pf/y5cvr9fj1zRV/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMpDNPv777rtvMu/atWtZx//Od76TzB944IFkPn/+/LLOXxcuu+yyRj1/ixbpn0OL9vGfPXt2Mi+VSrVeE/l64YUXkvmYMWOS+R133JHMJ0yYkMzvv//+ZF60voZQdH+Tqqqqej1/0dfw2muvTeb26eeTiv5Of/vb307mRxxxRDJ/4403kvlFF12UzHNQ1NfOO++8ej3/3Xffncx/8Ytf1Ov565sr/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGSg2ezj36lTp2Q+duzYZN6+ffuyzl+0p3Yl7NPf2EaNGpXMv/GNbyTzZcuWJfNTTz01mb///vvJHGrj0UcfTeZ//vOfk/nBBx+czK+88spkfswxxyTz119/PZnXxMiRI5P5GWeckczLvXfGbbfdlsyLvkaVcK8DKkuPHj2S+T333JPM+/fvn8xXrVqVzI8//vhk/oc//CGZNwdFfe2Xv/xlMu/YsWNdLudT/ud//ieZV1dX1+v565sr/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGSg2ezjv8022yTzbt26JfNy95u+9dZbk/mMGTOS+aWXXprMX3755VqvaW1bbbVV4XO23XbbZN65c+dk/txzzyXz4447LpkPHz48mT/++OPJHBrSihUrkvnRRx+dzItek/vss08ynzt3bjIv2i+8JvcuOf/885P5ZpttlsyL9tG/8cYbk/m4ceOS+QcffJDMyU/r1q2T+b333pvM+/Xrl8yL7idz0UUXJfN58+Yl8wEDBiTzcr300kvJvOjzq4kNN9wwmf/6179O5r179y57DSlFs7Po/iFNnSv+AACQAcUfAAAyoPgDAEAGFH8AAMiA4g8AABlQ/AEAIAOKPwAAZKCqVMMN7Kuqqup7LWXZbrvtkvnEiROT+Ve+8pWyzl/09Sn3PgHlqsn3r9LXePPNNyfzI444oi6XU3Ea+/vzSZU+EyrdyJEjk3nRXtKV8PehaJ/+CRMmJPNrr702mdunP60S/g58UmPPhZ/85CfJvOieOc3dzJkzk/nll19eeIy///3vyfywww5L5mPHji08Rzn+93//N5kPHjw4mb/zzjt1uZwGVzQXXPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkoNncwKtdu3bJ/Mc//nEyP+OMM8o6vht4le+9995L5oMGDUrmc+fOrcvlVJzG/v58UqXPhKbuwAMPTOa33357A63k81133XXJfPTo0Q20kjxV2kyIaPy5UPQ1qa6uLuv4K1euTOaPP/54WcevbxtuuGEy33rrrQuPUXTjvr59+9ZqTbV14403JvMf/OAHyby53xjQDbwAAADFHwAAcqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGSgVWMvoK68//77yfzqq69O5g888EAy33///ZP56aefnswpduGFFybz5r5PP6ztH//4RzJv7P3SIyL22muvZN6xY8dkvnz58rpcDsQFF1yQzHfeeedkftlllyXzoq7x8MMPJ/PG9sUvfjGZH3zwwYXHKPoaFXn99deT+YknnpjM77rrrmTe3PfpL5cr/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGSgqlQqlWr0xArYM7qSdevWLZn/27/9WzI//PDD63I5n/L8888XPudb3/pWMm/fvn1Zayi618Gll15a1vGbuxq+VBuMmVC//va3vyXzgQMHJvMlS5Yk86K9siMifvSjHyXzHXfcMZn/x3/8RzKfOHFi4Rr4fJU2EyLMhaZup512KnzOfffdl8xXrFiRzP/93/89mVf6vRAqXdFccMUfAAAyoPgDAEAGFH8AAMiA4g8AABlQ/AEAIAOKPwAAZEDxBwCADLRq7AU0F4sXL07mV199dVl5uXbdddfC5xx22GHJvGhv2NWrVyfzd955p3ANkIvLL788mRftpz179uxkvu+++ybzhQsXJvOarKFoH/9TTjklmd96663JfPny5ckcqJ2NN944mZ9//vmFx+jUqVMyL9rn3z79jcsVfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADJgH/9monfv3sn8nHPOKTxGmzZtylrDxIkTk3l936sAKkmPHj2SedEe+W+//XYy/9nPfpbMa7JPf5Gi1/TJJ5+czNu2bZvMq6qqarskoAyjRo1K5sOHDy/7HL/61a/KPgb1xxV/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMmAf/2aiU6dOyXzPPfcsPEapVCprDUV7fkNOivbDHjRoUDK/++67k/mMGTNqvaba2nbbbev9HEDdOeyww5L5L37xi7LPccQRRyTzBx98sOxzUH9c8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACAD9vFvJkaPHl32Md5///1k/t3vfjeZP/7442WvAZqLDTbYIJm3bds2mVdVVdXlctbLbrvtlsxbtEhfO6qEzwFycvjhhyfzjh07JvNXX3218ByPPvpoMl+xYkXhMWg8rvgDAEAGFH8AAMiA4g8AABlQ/AEAIAOKPwAAZEDxBwCADCj+AACQAfv4NxGDBw9O5t/85jeTeU32037wwQeT+cyZM5P5ypUrC88BuXjvvfeSealUSuYjRoxI5jvttFMynz59ejLfZZddknlExA477JDMq6urk/kDDzyQzD/44IPCNQD/MmDAgGQ+dOjQZL5o0aJkXtQlIiLmzZtX+Bwqlyv+AACQAcUfAAAyoPgDAEAGFH8AAMiA4g8AABlQ/AEAIAOKPwAAZKCqVLSZ9MdPrME+8Ky/tm3bJvO//OUvyXz77bdP5qtWrSpcw7e//e1kfssttxQeg/pTw5dqgzET0jbccMNkXnTfjKLX9JIlS5L5ddddl8wPOOCAZB4R8eUvfzmZv/HGG8m86F4BL730UuEa+HyVNhMizIX6dvzxxyfzq6++Opk/9NBDyXzIkCG1XhOVpWguuOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABuzjXyFOPPHEZD5u3Liyjj9t2rTC5xx88MHJfOnSpWWtgfJU2p7dZkJ5vvSlLyXz5557Lpk3xN+HV199NZnfd999yfw73/lOXS6HT6i0mRBhLpSrf//+yfypp55K5q1bt07mBx10UDL/wx/+kMypfPbxBwAAFH8AAMiB4g8AABlQ/AEAIAOKPwAAZEDxBwCADCj+AACQgVaNvQA+0qtXr7I+fsmSJcn8lFNOKTyGffqh4cybNy+Zb7vttsn8xhtvTObbbLNNMp80aVIyj4iYMWNGMr/11lsLjwHU3BlnnJHMi/bp/+1vf5vM586dW+s10by44g8AABlQ/AEAIAOKPwAAZEDxBwCADCj+AACQAcUfAAAyoPgDAEAG7OPfRBTt03/ggQcm86effroOVwPUtzlz5iTzXXbZpYFWAjSUon36Fy1alMx//vOfJ/MXXnih1muieXHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAxUlUqlUo2eWFVV32sBEmr4Um0wZgI0rkqbCRHmAjS2orngij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZqPE+/gAAQNPlij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOLfRJxzzjlRVVW1Xh87adKkqKqqipdeeqluFwU0GjMBWJuZQE0o/o3g4xfYx3/atWsXm222Wey9995x1VVXxbvvvlvva5gwYUJMmjSp7ONUV1fH2LFjo0+fPtGuXbvYbrvt4uabby5/gZCR5jQTIiLmzZsXhx9+eHTt2jXat28fW265ZYwZM6ZOjg05aE4zQU+oLFWlUqnU2IvIzaRJk+LYY4+N8847L/r06RMrV66MRYsWxYMPPhj33ntvbL755nHnnXfGdtttt+ZjVq1aFatWrYp27drV+nyrV6+OlStXRtu2bddcDRgwYEB06dIlHnzwwbI+l9NPPz0uueSSOO6442LQoEFxxx13xB//+Me4+eab49BDDy3r2JCL5jQTnnrqqdhjjz2iR48ecfTRR8fGG28cL7/8cixYsCAmTpxY1rEhF81pJugJFaZEg5s4cWIpIkqPPvrop7L777+/1L59+1Lv3r1L7733Xr2tYZtttintvvvuZR3jlVdeKbVu3bp0wgknrHmsurq6tNtuu5V69uxZWrVqVZmrhDw0l5mwevXq0oABA0pf/epX63Wt0Nw1l5mgJ1Qeb/WpMEOHDo2f//znMX/+/JgyZcqaxz/rvXsrVqyIk046Kbp06RKdOnWKESNGxMKFC6OqqirOOeecNc/75Hv3tthii5g9e3ZMnz59zT8j7rHHHmueP2/evJg3b17hWu+4445YuXJljB49es1jVVVV8f3vfz9eeeWV+Mtf/rJ+XwRgjaY0E+655554+umn4+yzz4727dvHe++9F6tXry7r8wfW1ZRmgp5QeRT/CnTUUUdFxEf/E0055phjYvz48bHffvvFpZdeGu3bt4/999+/8Pjjxo2Lnj17Rv/+/WPy5MkxefLkdd5/O2zYsBg2bFjhcZ588sno2LFjfPnLX17n8Z133nlNDpSvqcyE++67LyIi2rZtGzvttFN07NgxOnToEIceemi89dZbhR8P1ExTmQl6QuVp1dgL4NN69uwZnTt3Tv40/cQTT8Stt94aJ598clxxxRURETF69Og49thjY9asWcnjjxw5Ms4888zo0qVLHHnkkeu9ztdeey26dev2qSsMm266aUREvPrqq+t9bOBfmspMeP755yMi4pBDDol99tknTj/99Jg1a1ZcfPHFsWDBgnj44YfXe9cR4F+aykzQEyqPK/4VaoMNNkj+1v7dd98dEbHOP59FRJx44olln/ull16q0ZZeK1asiLZt237q8Y9/sWjFihVlrwX4SFOYCcuWLYuIiEGDBsWUKVNi1KhRcd5558X5558fM2fOjPvvv7/stQAfaQozQU+oPIp/hVq2bFl06tTpc/P58+dHixYtok+fPus83rdv3/pe2hrt27ePDz744FOPv//++2tyoG40lZkQEXHYYYet8/jhhx8eEREzZ85ssLVAc9dUZoKeUFkU/wr0yiuvxNKlSxv0xbk+Nt1001i0aFGUPrEj7GuvvRYREZtttlljLAuanaYyEz5+zXfr1m2dx7t27RoREW+//XaDrwmao6YyE/SEyqP4V6DJkydHRMTee+/9uc/p3bt3VFdXx4svvrjO4y+88EKNzlEX77P9yle+Eu+9914888wz6zz+t7/9bU0OlK+pzISBAwdGRMTChQvXefzj9/FusskmZZ8DaDozQU+oPIp/hZk2bVqcf/750adPnzjiiCM+93kfv9gnTJiwzuPjx4+v0Xk6duwYS5Ys+cysptt0HXTQQdG6det11lAqleKaa66JHj16xK677lqjtQCfr6nNhLZt28bEiROjurp6zeM33HBDRETstddeNVoL8Pma2kzQEyqLXX0a0dSpU2Pu3LmxatWqWLx4cUybNi3uvffe6N27d9x5553Ju+8NHDgwRo0aFePGjYs333wzdtlll5g+fXo899xzEVH8k/rAgQPj6quvjgsuuCD69u0bXbt2jaFDh0ZErNmiq+gXd3r27Bknn3xyXHbZZbFy5coYNGhQ/P73v48ZM2bETTfdFC1btqzFVwNo6jOhe/fuMWbMmDjrrLNin332iZEjR8asWbPi+uuvj8MOOywGDRpUi68G0NRngp5QgRr3/mF5+viOfB//adOmTal79+6lvfbaq3TllVeW3nnnnU99zNlnn1365Ldr+fLlpRNOOKG00UYblTbYYIPSyJEjS88++2wpIkqXXHLJp8734osvrnls0aJFpf3337/UqVOnUkSsc3e+3r17l3r37l2jz2X16tWliy66qNS7d+9SmzZtSttss01pypQptfp6QO6a00yorq4ujR8/vrTVVluVWrduXerVq1fpzDPPLH344Ye1+ppAzprTTNATKktVqfSJ37igSXvqqadihx12iClTpiT/CRDIg5kArM1MyJv3+Ddhn7X/7bhx46JFixYxePDgRlgR0JjMBGBtZgKf5D3+TdjYsWPj8ccfjyFDhkSrVq1i6tSpMXXq1Dj++OOjV69ejb08oIGZCcDazAQ+yVt9mrB77703zj333JgzZ04sW7YsNt988zjqqKNizJgx0aqVn+kgN2YCsDYzgU9S/AEAIAPe4w8AABlQ/AEAIAOKPwAAZEDxBwCADNT4V7qLbu0M1K9K+z18MwEaV6XNhAhzARpb0VxwxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABkoFVjLwCA5qlnz57JvF+/fsn89ttvT+YbbLBBMq+qqkrmM2fOTOZf//rXkzlAU+OKPwAAZEDxBwCADCj+AACQAcUfAAAyoPgDAEAGFH8AAMiA4g8AABmwj38mRowYUficoUOHJvNevXol829+85vJ/PDDD0/mt9xySzIHKsupp56azAcPHpzM99lnn7LOXyqVysqrq6vLOj9AU+OKPwAAZEDxBwCADCj+AACQAcUfAAAyoPgDAEAGFH8AAMiA4g8AABmoKhVtdPzxE6uq6nstJGywwQbJ/OKLL07mxxxzTOE5OnbsmMxr+Fflc3344YfJfO+9907mDz30UFnnb+rK/frXNTOhcbVp0yaZt2qVvk3L8OHDC8/xs5/9LJnvsMMOybxojY1t6dKlyfzHP/5xMp84cWJdLqfWKm0mRJgL5Ro/fnwyL7onT9HHF/2dP/PMM5N5RPH3+Lzzzkvmt99+ezJ/8803C9fA5yuaC674AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAH7+FeI1q1bJ/Nbb701mRft7VsTc+bMSeZbb711Mp8yZUoy32yzzZL5wQcfnMyL9h9u7iptz24zoX4VvV6uv/76ZL7PPvvU5XKapZkzZybz3XbbrYFWsn4qbSZEmAtbbbVVMt9oo42S+SOPPJLMK+F7XvQ9Llrj7Nmzk/mECROS+Z133pnMX3vttWTe3NnHHwAAUPwBACAHij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABuzjXyEOOuigZP673/0umX/44YfJ/Jhjjilcw7Rp05L5HXfckcz79OmTzFetWpXMf/3rX5eVP/vss8m8qauE/ZvXZiaU56c//WkyHzx4cDLfb7/96nI5WTr66KOT+U033dRAK1k/lTYTIpr/XOjWrVsyL7q/RtHrttw98htCY69x1qxZyXzYsGHJfMmSJXW4mspjH38AAEDxBwCAHCj+AACQAcUfAAAyoPgDAEAGFH8AAMiA4g8AABmwj38DGTVqVDKfPHlyMm/btm0yP+GEE5L5Nddck8wbwoknnpjMx40bl8xffvnlZL799tsn83feeSeZV7pK2L95bc19JhR9fhtttFEyHz16dDL/2c9+lsw7dOiQzJuDd999N5nvv//+ZX18kaeffjqZV1dXl3X8+lZpMyGi+c+FRx55JJl/9atfLev4jb1Hfk1U+hqffPLJZL7nnnsm86VLl9blchqcffwBAADFHwAAcqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGTAPv51pEuXLsl85syZyfxLX/pSMv/Tn/6UzI844ohkXgl72Ldu3TqZX3755cm86F4Fv/zlL5P5SSedlMwrXWPvjfxJzX0mFO2jX+4e8s3BXXfdlczff//9ZF50746//vWvtV1SViptJkQ0/blwyCGHJPObb765Xs/fokX6emy595a46aabkvnRRx9deIzdd989mR944IHJ/LDDDkvm3bt3L1xDStHXsGif/6L7h7z22mu1XlNDso8/AACg+AMAQA4UfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAM2Me/hoo+/4kTJybzo446KpkvXbo0mffo0SOZr1ixIpk3Bb169Urm06dPT+abbbZZMt9ll12S+VNPPZXMG1ul7dnd3GdCc9/Hv+jeIhERU6ZMKStfvnx5rdZE7VTaTIio/Lmw1VZbJfM//vGPybxPnz51uZxPKfr6FX3Pb7zxxmT+wx/+MJk3RJfYZJNNkvmJJ56YzM8444xkXu7XsOieQddee20yb2z28QcAABR/AADIgeIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkIFWjb2ApuLLX/5yMi/ap7/I+eefn8ybwz79RRYsWJDMi/bWveOOO5L53nvvncwrfR9/aqddu3bJ/LTTTkvmhx9+eF0up869/fbbyfzFF19M5gcffHDhORYvXlyrNdW1ovuXFN0nYMmSJXW4GpqD/fffP5nX9z79RW655ZZkftVVVyXz2bNnJ/NK6BKvv/56Mr/++uuTedE+/uW65JJLkvmHH36YzIvu69TYXPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA1WlUqlUoydWVdX3WiraM888k8y32mqrZP7AAw8k8/322y+ZF+0bS8SiRYuSedH+xYMGDUrmb7zxRq3XVJdq+FJtMJU+E4YNG5bM77nnngZayfp56aWXkvl3v/vdZP7oo48m85rs49/Yxo8fn8wffvjhZP6b3/wmmf/zn/9M5lOnTk3mja3SZkJE5c+FU045JZlfdtll9Xr+ontLFM2tWbNm1eFqKlOHDh2SeVFfuvbaa5N5586da72mtRXdc6ix7wVRNBdc8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADrRp7AU1Fz549y/r4P//5z8ncPv31b/PNN0/m2267bTIvuhcD1MayZcuS+bHHHpvM/8//+T/JfPTo0cl81KhRybwp2HvvvcvKX3/99WR+wgknJPPbbrstmVN5RowYUa/HL9qnf/jw4ck8h336i7z33nvJ/Le//W0y79WrVzIv914NX/jCF5L57rvvnsynT59e1vnL5Yo/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGbCP//9v8uTJybxjx47JfP78+WUdn/JVVVUl8xYt/Jybk1tuuaWxl5DUoUOHZD5lypRkXrSXdNHMImKTTTZJ5r/61a+S+WuvvZbMZ86cWes1Ub/22GOPZF5dXV3W8ZcvX57Mn3jiibKOT/mKukKRDTfcMJlPmzYtmbds2bKs85dLEwIAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGQgmxt4bb/99sn8wAMPTOalUimZX3fddcl80aJFyZzyFX2P3n333WT+9ttv1+VyaGQbb7xxMi/6+1Lfim4o16NHjwZaCZ+nU6dOybxt27YNtBLqStENusqdC+XeAIz619izv7G54g8AABlQ/AEAIAOKPwAAZEDxBwCADCj+AACQAcUfAAAyoPgDAEAGstnHv0uXLsm8aL/mIi+++GJZH0/9u+uuu5L5U0891TALAaBRzJ8/P5lvvvnmDbQSPs/OO++czK+44opkvummm9blcpodV/wBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIQDb7+O+6665lffzrr7+ezH/729+WdXwiWrduncz/8z//M5lvsskmyXzatGm1XhM0VR9++GEynzNnTuExxo4dm8wfeuihZN6/f/9kftZZZyXzwYMHJ/P6tnjx4mT+7rvvNtBKqCvjx49P5pdddllZx2/VKl2revXqlcwXLFhQ1vkbQtF9j3bfffdkftRRRyXzr371q8m8Z8+eybyqqiqZl0qlZF6uJUuW1Ovxy+WKPwAAZEDxBwCADCj+AACQAcUfAAAyoPgDAEAGFH8AAMiA4g8AABnIZh//on1fixTt+7pq1aqyjk/EwIEDk/no0aOTeXV1dTIvuhcDzUvRvTVGjRrVQCtpHO+9914ynzJlSuExNttss2R+4oknJvNTTz218ByV7IYbbkjmjz32WAOthLoyffr0ZL506dJk3rlz52S+6aabJvMXX3wxmV955ZXJvL73oK+Jov9X77bbbg20ksZRtE//8OHDG2Yh68kVfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADJQVarhprBVVVX1vZZ6NWzYsGR+zz33JPN33nknmX/lK19J5vPnz0/mOdhll12S+fXXX5/Mt95662R+2mmnJfPLLrssmVe6Sti/eW2VPhPKfc3T/M2ZMyeZF93r4bnnnqvL5dRapc2EiMqfC0UmT56czA8//PB6PX+LFunrsUX3q2kIlb7G+l7fTTfdlMyPPvroso5frqK54Io/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGWjV2AtoKKtXr07mRfuebrjhhsl8jz32SOZTpkxJ5kXrqwTt2rVL5sccc0wyv/jii5N50dd41qxZyXzChAnJnLwsXbo0mS9cuDCZ9+jRoy6XQz149dVXk/mRRx6ZzP/yl78k8w8//LDWa6JpO/7445N50dw49NBDk3nPnj2TedEe85Vw74ZKX2PR+u66665kPnbs2GT+5JNP1npNlcQVfwAAyIDiDwAAGVD8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADJQVarhhqtVVVX1vZZGddZZZ5WVF319ivaNLdqPutw96nfYYYfC5wwePDiZ77XXXsm8V69etVrTJz366KPJfMSIEcn8n//8Z1nnr3SNvTfyJzX1mVD09/lXv/pVMrfPf/27/PLLk/m0adOS+d13312Xy6k4lTYTIpr+XCjXTjvtlMyvuOKKZL7rrrsm8zfeeCOZX3PNNcl8zJgxybwmir7H5f69/OCDD5L5E088kcx/+tOflvXxTf3+HUVff1f8AQAgA4o/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIB9/Gvo97//fTI/8MADG2Yh9ajcvXlffvnlZF60v/CkSZOS+eLFi5N5c1dpe3Y395lQtJ/2jBkzGmgllWvBggXJ/Nhjjy3r+A8//HAyX7lyZVnHb+oqbSZENP+5UN8OPvjgZP7KK68k8+effz6Z33jjjcl8u+22S+YRES1apK8ZV1dXJ/Orrroqmc+dOzeZT506NZnnzj7+AACA4g8AADlQ/AEAIAOKPwAAZEDxBwCADCj+AACQAcUfAAAyYB//GmrZsmUyP/7445P5AQcckMz32WefWq+prhXtrVu0T//kyZOT+RtvvFHrNfEvlbZnd+4zARpbpc2ECHMBGpt9/AEAAMUfAAByoPgDAEAGFH8AAMiA4g8AABlQ/AEAIAOKPwAAZMA+/tBEVNqe3WYCNK5KmwkR5gI0Nvv4AwAAij8AAORA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIgOIPAAAZUPwBACADij8AAGRA8QcAgAwo/gAAkAHFHwAAMqD4AwBABhR/AADIQFWpVCo19iIAAID65Yo/AABkQPEHAIAMKP4AAJABxR8AADKg+AMAQAYUfwAAyIDiDwAAGVD8AQAgA4o/AABk4P8Dfcr2NhmYXHAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 60000\n",
            "Total test samples: 10000\n"
          ]
        }
      ],
      "source": [
        "from data import get_data, prepare_data_loaders\n",
        "\n",
        "# Get preprocessed MNIST data\n",
        "data = get_data()\n",
        "\n",
        "# Create PyTorch DataLoaders\n",
        "train_loader, test_loader = prepare_data_loaders(data, batch_size=64)\n",
        "\n",
        "# Function to display a grid of images\n",
        "def display_mnist_samples(images, labels, grid_size=(3, 3)):\n",
        "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(8, 8))\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < len(images):\n",
        "            # Remove the extra dimension and display the image\n",
        "            ax.imshow(images[i].squeeze(), cmap='gray')\n",
        "            # Get the original label (not one-hot encoded)\n",
        "            label = np.argmax(labels[i])\n",
        "            ax.set_title(f\"Digit: {label}\")\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display a few samples from the training set\n",
        "num_samples = 9\n",
        "indices = np.random.choice(len(data.x_train), num_samples, replace=False)\n",
        "sample_images = data.x_train[indices]\n",
        "sample_labels = data.y_train[indices]\n",
        "\n",
        "# Display the images\n",
        "display_mnist_samples(sample_images, sample_labels)\n",
        "\n",
        "# Print some information about the dataset\n",
        "print(f\"Total training samples: {len(data.x_train)}\")\n",
        "print(f\"Total test samples: {len(data.x_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwDVDhuTebhP"
      },
      "source": [
        "## 2.2 Defining the model\n",
        "\n",
        "We can now define our model. We will use a small, simple Convolutional Neural Network with dropout as shown below:\n",
        "\n",
        "```\n",
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(3872, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        x = self.conv_layers(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "def build_model():\n",
        "    model = MNISTModel()\n",
        "    return model\n",
        "\n",
        "```\n",
        "This network model has been defined in the file `model.py` and we will call it later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJtxVA7Qm3oz"
      },
      "source": [
        "## 2.3 Defining the uncertainty functions\n",
        "\n",
        "### 2.3.1 Epistemic or knowledge uncertainty\n",
        "\n",
        "We will use epistemic uncertainty (also called knowledge\n",
        "uncertainty) as one of our main uncertainty functions to acquire new\n",
        "samples. Let us define the function to compute epistemic uncertainty\n",
        "over our predictions.\n",
        "\n",
        "We define the followoing terms and notations:\n",
        "- $\\omega$: Model parameters (weights and biases)\n",
        "- $p(y = c|x, \\omega)$: Probability of input $x$ belonging to class $c$ with model parameters $\\omega$\n",
        "- $q_\\theta^*(\\omega)$: Approximate posterior distribution over model parameters\n",
        "- $\\hat{\\omega}_t \\sim q_\\theta^*(\\omega)$: A sample of weights drawn from the approximate posterior\n",
        "- $\\hat{p}_c^t = p(y = c|x, \\hat{\\omega}_t)$: Predicted probability for class $c$ using sampled weights $\\hat{\\omega}_t$ in MC dropout\n",
        "- $T$: Total number of Monte Carlo dropout forward passes\n",
        "- $C$: Number of classes\n",
        "\n",
        "### Total Uncertainty\n",
        "\n",
        "The total predictive uncertainty is captured by the entropy of the expected predictive distribution (Max Entropy, (Shannon, 1948)):\n",
        "\n",
        "$$H[y|x, D_{\\text{train}}] = -\\sum_{c} p(y = c|x, D_{\\text{train}}) \\log p(y = c|x, D_{\\text{train}})$$\n",
        "\n",
        "This can be approximated using $T$ forward passes with MC dropout:\n",
        "\n",
        "$$H[y|x, D_{\\text{train}}] \\approx -\\sum_{c} \\left(\\frac{1}{T}\\sum_{t=1}^{T} \\hat{p}_c^t\\right) \\log \\left(\\frac{1}{T}\\sum_{t=1}^{T} \\hat{p}_c^t\\right)$$\n",
        "\n",
        "### Data Uncertainty (Aleatoric)\n",
        "\n",
        "Data uncertainty represents the inherent noise in the data, approximated as the expected entropy of individual predictions (Gal, 2016, pp. 48–52):\n",
        "\n",
        "$$E_{p(\\omega|D_{\\text{train}})}[H[y|x, \\omega]] \\approx \\frac{1}{T}\\sum_{t=1}^{T} \\left(-\\sum_{c} \\hat{p}_c^t \\log \\hat{p}_c^t\\right)$$\n",
        "\n",
        "### Knowledge Uncertainty (Epistemic)\n",
        "\n",
        "Knowledge uncertainty is the mutual information between predictions and model posterior, which is the BALD acquisition function (Houlsby et al., 2011) in the paper (which is Total `Uncertainty` - `Data Uncertainty`) :\n",
        "\n",
        "$$I[y, \\omega|x, D_{\\text{train}}] = H[y|x, D_{\\text{train}}] - E_{p(\\omega|D_{\\text{train}})}[H[y|x, \\omega]]$$\n",
        "\n",
        "This quantity represents the uncertainty in the model parameters, which can be reduced by acquiring more data. This is why it serves as an effective acquisition function for active learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX6dZv9docfe"
      },
      "source": [
        "Knowledge uncertainty will be used as acquisition function in the active learning loop. To compute it, we first need the weights obtained through MC dropout.\n",
        "\n",
        "`get_mc_predictions` uses MC droupout to generate the necessary prediction distribution (multiple predictions per sample) that the uncertainty functions need as input. It creates the `preds` tensor $\\hat{p}_c^t$ with shape (n_samples, n_mc_passes, n_classes) that is directly passed to `total_uncertainty`, `data_uncertainty`, and `knowledge_uncertainty`. Without these stochastic samples $\\hat{p}_c^t$ from dropout, we could not calculate these different uncertainty types for active learning sample selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g5l4I5AKea0e"
      },
      "outputs": [],
      "source": [
        "def get_mc_predictions(model: nn.Module, n_iter: int, x_train: torch.Tensor) -> torch.Tensor:\n",
        "    device = next(model.parameters()).device\n",
        "    preds = []\n",
        "    # Set model to training mode to enable dropout\n",
        "    model.train()\n",
        "    with torch.no_grad():\n",
        "        for _ in tqdm(range(n_iter)):\n",
        "            # Split data into batches\n",
        "            preds_iter = []\n",
        "            for batch in torch.chunk(x_train, chunks=6):\n",
        "                batch = batch.to(device)\n",
        "                # Ensure input is float and has correct shape (add channel dim if needed)\n",
        "                if len(batch.shape) == 3:\n",
        "                    batch = batch.unsqueeze(1)\n",
        "                preds_iter.append(model(batch))\n",
        "            # Concatenate batch predictions\n",
        "            preds.append(torch.cat(preds_iter, dim=0))\n",
        "    # Stack predictions and move axes to get (n_images, n_predictions, n_classes)\n",
        "    preds = torch.stack(preds, dim=1)\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRBdrvHJrxa5"
      },
      "source": [
        "**Question 3 (10 marks)**\n",
        "\n",
        "Write the code for the functions `data_uncertainty` and `total_uncertainty` below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIFIwo0vsZ9O"
      },
      "source": [
        "*Solution*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fUTwyZ5gsb8v"
      },
      "outputs": [],
      "source": [
        "def total_uncertainty(preds: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n",
        "    mean_preds = preds.mean(dim=1)\n",
        "    entropy_mean = -torch.sum(mean_preds * torch.log(mean_preds + 1e-12), dim=1)\n",
        "    return entropy_mean\n",
        "\n",
        "def data_uncertainty(preds: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n",
        "    entropy_per_pass = -torch.sum(preds * torch.log(preds + 1e-12), dim=2)\n",
        "    mean_entropy = entropy_per_pass.mean(dim=1)\n",
        "    return mean_entropy\n",
        "\n",
        "def knowledge_uncertainty(preds: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n",
        "    # Knowledge uncertainty is the difference between total and data uncertainty\n",
        "    return total_uncertainty(preds, epsilon) - data_uncertainty(preds, epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj1R4fJVunBJ"
      },
      "source": [
        "The acquisition function that uses the knowledge uncertainty function can be summarised in three steps\n",
        "1. Obtain an ensemble of predictions via MC dropout (done by `get_mc_predictions`).\n",
        "2. Compute the knowledge uncertainty values over this prediction\n",
        "ensemble (use `knowledge_uncertainty` function).\n",
        "3. Sort the uncertainty values, get their index and return the\n",
        "indices of the data in the pool with the highest epistemic\n",
        "uncertainty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1xoliVEgvDjE"
      },
      "outputs": [],
      "source": [
        "def acquire_knowledge_uncertainty(\n",
        "    x_train: torch.Tensor, n_samples: int, model: nn.Module, n_iter: int, *args, **kwargs\n",
        "):\n",
        "    # Get Monte Carlo predictions\n",
        "    preds = get_mc_predictions(model, n_iter, x_train)\n",
        "    # Compute knowledge uncertainty\n",
        "    ku = knowledge_uncertainty(preds)\n",
        "    # Get indices of samples with highest uncertainty\n",
        "    _, indices = torch.topk(ku, n_samples)\n",
        "    return indices.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ2sLahwvb2G"
      },
      "source": [
        "### 2.3.2 Laplace uncertainty\n",
        "\n",
        "Rather than using MC dropout to compute samples on the parameters of the neural network, we can use a Laplace approximation, which approximates the posterior distribution of the parameters using a Gaussian distribution.\n",
        "\n",
        "The predictive distribution under a Bayesian approach (Gal, 2016) can be written as:\n",
        "\n",
        "$$p(y=c|x, D_{train}) = \\int p(y=c|x, \\omega)p(\\omega|D_{train})d\\omega.$$\n",
        "\n",
        "With Laplace approximation, we approximate the posterior $p(\\omega|D_{train})$ with a **Gaussian distribution** $N$ centered at the MAP estimate:\n",
        "\n",
        "$$p(\\omega|D_{train}) \\approx N(\\omega|\\omega_{MAP}, \\Sigma_{post}),$$\n",
        "\n",
        "where:\n",
        "- $\\omega_{MAP}$ is the maximum a posteriori estimate of the parameters\n",
        "- $\\Sigma_{post}$ is the covariance matrix computed at $\\omega_{MAP}$.\n",
        "\n",
        "We can then use this posterior distribution and the probit likelihood to approximate the posterior probabilities over the classes.\n",
        "\n",
        "Computing the Laplace approximation for a posterior distribution of a neural network is cumbersome in general. Here, we use a recent package known as [Laplace that allows to compute the posterior distribution effortlessly](https://github.com/AlexImmer/Laplace).\n",
        "\n",
        "### Uncertainty Measure for Acquisition when using the Laplace approximation\n",
        "\n",
        "We use Max Entropy (Shannon, 1948) as an uncertainty measure in this case:\n",
        "\n",
        "$$H[y|x, D_{train}] := -\\sum_{c} p(y=c|x, D_{train}) \\log p(y=c|x, D_{train})$$\n",
        "\n",
        "This acquisition function selects pool points that maximize the predictive entropy.\n",
        "\n",
        "The acquisition function that uses the max entropy with Laplace approximation can be summarised in three steps\n",
        "1. Obtain the predictions under the posterior distribution via Laplace approximation.\n",
        "2. Compute the max entropy values for the datapoints in the pool.\n",
        "3. Sort the uncertainty values, get their index and return the\n",
        "indices of the data in the pool with the highest epistemic\n",
        "uncertainty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b79xKKJ_y28d"
      },
      "source": [
        "**Question 4 (10 marks)**\n",
        "\n",
        "The following acquisition function implements the three steps above. Write the code for steps 1 and 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrKP59HFzY3a"
      },
      "source": [
        "*Solution*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vel9qdWnzetR"
      },
      "outputs": [],
      "source": [
        "def acquire_laplace_uncertainty(\n",
        "    unlabeled_tensor: torch.Tensor, n_samples: int, la_model: Laplace) -> np.ndarray:\n",
        "    try:\n",
        "        # Step 1: Predict probabilities with error handling\n",
        "        #\n",
        "        preds = la_model.predictive_samples(unlabeled_tensor, n_samples=1000).mean(0)\n",
        "        # Convert to numpy with checks\n",
        "        try:\n",
        "            preds_np = preds.numpy()\n",
        "        except Exception:\n",
        "            preds_np = preds.detach().cpu().numpy()\n",
        "\n",
        "        # Step 2: Entropy calculation\n",
        "        #\n",
        "        #\n",
        "        uncertainty = -np.sum(preds_np * np.log(preds_np + 1e-12), axis=1)\n",
        "\n",
        "        # Step 3: Select indices with highest uncertainty\n",
        "        indices = np.argsort(uncertainty)[-n_samples:]\n",
        "        return indices\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Laplace Acquisition Error: {e}\")\n",
        "        # Fallback to random sampling\n",
        "        return np.random.choice(len(unlabeled_tensor), n_samples, replace=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4kW5teXvV0G"
      },
      "source": [
        "### 2.3.3 Random selection\n",
        "\n",
        "The simplest approach to select a datapoint from the pool is to do it randomly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BcYSrEflv6yB"
      },
      "outputs": [],
      "source": [
        "def acquire_random(x_train: torch.Tensor, n_samples: int, *args, **kwargs) -> np.ndarray:\n",
        "    # Randomly select samples\n",
        "    return torch.randperm(len(x_train))[:n_samples].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBxvOwlC0VF9"
      },
      "source": [
        "### 2.3.4 A battery of acquisition functions\n",
        "\n",
        "We can group the three acquisition functions above in a function,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-9XaUHhP0i9I"
      },
      "outputs": [],
      "source": [
        "def acquisition_factory(acquisition_type: str) -> Callable:\n",
        "    if acquisition_type == \"laplace_uncertainty\":\n",
        "        return acquire_laplace_uncertainty\n",
        "    if acquisition_type == \"knowledge_uncertainty\":\n",
        "        return acquire_knowledge_uncertainty\n",
        "    elif acquisition_type == \"random\":\n",
        "        return acquire_random\n",
        "    else:\n",
        "        raise ValueError(f\"Acquisition type {acquisition_type} not supported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKVgY-nj1FNy"
      },
      "source": [
        "Now that we have defined our acquisition functions, we are ready\n",
        "to define the loop that runs the active learning iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXLq8vB71Sdy"
      },
      "source": [
        "## 2.4 Main Loop for Active Learning\n",
        "\n",
        "We will start our dataset with 20 samples until we reach a total of 500 samples. Each model will be trained for 25 epochs and per iteration, we acquire 10 samples. To obtain our MC dropout predictions, we will run over\n",
        "our full training set (minus the already acquired samples) 48 times.\n",
        "\n",
        "It will take you approx. 1 hour to finish the active learning loop using standard colab T4 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3h0GbKNr07QC"
      },
      "outputs": [],
      "source": [
        "import main\n",
        "main.acquisition_factory= acquisition_factory #Put your acquisition functions inside the main module\n",
        "from main import Active_learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d0-JRBWt51ar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17ba4530-b7f9-4764-a509-fcb9088577db"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Model directory: models/laplace_uncertainty/f495ac8f-2dd6-45f4-8142-5ac2d4c0ddb4\n",
            "Laplace_Uncertainty Iteration 1/48\n",
            "Epoch 1/50 - Loss: 2.3037 - Acc: 0.0000 - Val Loss: 2.2881 - Val Acc: 0.1737\n",
            "Epoch 25/50 - Loss: 0.3443 - Acc: 0.8500 - Val Loss: 2.0637 - Val Acc: 0.5400\n",
            "Epoch 50/50 - Loss: 0.0467 - Acc: 1.0000 - Val Loss: 2.5550 - Val Acc: 0.5379\n",
            "Laplace approximation fitted\n",
            "Iteration 1: Added 10 samples - Accuracy: 53.79%\n",
            "Laplace_Uncertainty Iteration 2/48\n",
            "Epoch 1/50 - Loss: 2.3125 - Acc: 0.1667 - Val Loss: 2.2939 - Val Acc: 0.1280\n",
            "Epoch 25/50 - Loss: 0.1497 - Acc: 0.9667 - Val Loss: 1.7968 - Val Acc: 0.5454\n",
            "Epoch 50/50 - Loss: 0.0185 - Acc: 1.0000 - Val Loss: 2.3548 - Val Acc: 0.5740\n",
            "Laplace approximation fitted\n",
            "Iteration 2: Added 10 samples - Accuracy: 57.40%\n",
            "Laplace_Uncertainty Iteration 3/48\n",
            "Epoch 1/50 - Loss: 2.3096 - Acc: 0.1000 - Val Loss: 2.2937 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.1792 - Acc: 0.9750 - Val Loss: 1.2866 - Val Acc: 0.6421\n",
            "Epoch 50/50 - Loss: 0.0830 - Acc: 0.9500 - Val Loss: 1.5479 - Val Acc: 0.6766\n",
            "Laplace approximation fitted\n",
            "Iteration 3: Added 10 samples - Accuracy: 67.66%\n",
            "Laplace_Uncertainty Iteration 4/48\n",
            "Epoch 1/50 - Loss: 2.2877 - Acc: 0.1200 - Val Loss: 2.3029 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.0792 - Acc: 0.9800 - Val Loss: 1.4871 - Val Acc: 0.6290\n",
            "Epoch 50/50 - Loss: 0.0246 - Acc: 1.0000 - Val Loss: 1.7044 - Val Acc: 0.6503\n",
            "Laplace approximation fitted\n",
            "Iteration 4: Added 10 samples - Accuracy: 65.03%\n",
            "Laplace_Uncertainty Iteration 5/48\n",
            "Epoch 1/50 - Loss: 2.2407 - Acc: 0.2000 - Val Loss: 2.3533 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.0890 - Acc: 1.0000 - Val Loss: 1.3606 - Val Acc: 0.6462\n",
            "Epoch 50/50 - Loss: 0.0094 - Acc: 1.0000 - Val Loss: 1.6915 - Val Acc: 0.6466\n",
            "Laplace approximation fitted\n",
            "Iteration 5: Added 10 samples - Accuracy: 64.66%\n",
            "Laplace_Uncertainty Iteration 6/48\n",
            "Epoch 1/50 - Loss: 2.1194 - Acc: 0.3143 - Val Loss: 3.0915 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.1275 - Acc: 0.9857 - Val Loss: 1.1805 - Val Acc: 0.6595\n",
            "Epoch 50/50 - Loss: 0.0203 - Acc: 1.0000 - Val Loss: 1.6810 - Val Acc: 0.6761\n",
            "Laplace approximation fitted\n",
            "Iteration 6: Added 10 samples - Accuracy: 67.61%\n",
            "Laplace_Uncertainty Iteration 7/48\n",
            "Epoch 1/50 - Loss: 2.2349 - Acc: 0.2125 - Val Loss: 2.4082 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.1664 - Acc: 0.9375 - Val Loss: 1.3952 - Val Acc: 0.6261\n",
            "Epoch 50/50 - Loss: 0.0313 - Acc: 0.9875 - Val Loss: 1.4727 - Val Acc: 0.6832\n",
            "Laplace approximation fitted\n",
            "Iteration 7: Added 10 samples - Accuracy: 68.32%\n",
            "Laplace_Uncertainty Iteration 8/48\n",
            "Epoch 1/50 - Loss: 2.1912 - Acc: 0.3222 - Val Loss: 2.4524 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.0867 - Acc: 0.9778 - Val Loss: 1.4100 - Val Acc: 0.6359\n",
            "Epoch 50/50 - Loss: 0.0499 - Acc: 0.9889 - Val Loss: 1.9172 - Val Acc: 0.6135\n",
            "Laplace approximation fitted\n",
            "Iteration 8: Added 10 samples - Accuracy: 61.35%\n",
            "Laplace_Uncertainty Iteration 9/48\n",
            "Epoch 1/50 - Loss: 2.0338 - Acc: 0.4500 - Val Loss: 3.2374 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.1953 - Acc: 0.9500 - Val Loss: 1.3761 - Val Acc: 0.5939\n",
            "Epoch 50/50 - Loss: 0.0740 - Acc: 0.9800 - Val Loss: 1.4985 - Val Acc: 0.5970\n",
            "Laplace approximation fitted\n",
            "Iteration 9: Added 10 samples - Accuracy: 59.70%\n",
            "Laplace_Uncertainty Iteration 10/48\n",
            "Epoch 1/50 - Loss: 2.0560 - Acc: 0.3818 - Val Loss: 3.0301 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.0776 - Acc: 0.9909 - Val Loss: 1.2716 - Val Acc: 0.6603\n",
            "Epoch 50/50 - Loss: 0.0176 - Acc: 1.0000 - Val Loss: 1.5358 - Val Acc: 0.6552\n",
            "Laplace approximation fitted\n",
            "Iteration 10: Added 10 samples - Accuracy: 65.52%\n",
            "Laplace_Uncertainty Iteration 11/48\n",
            "Epoch 1/50 - Loss: 2.1074 - Acc: 0.2583 - Val Loss: 2.9082 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.0915 - Acc: 0.9750 - Val Loss: 1.5231 - Val Acc: 0.6277\n",
            "Epoch 50/50 - Loss: 0.0233 - Acc: 1.0000 - Val Loss: 1.8539 - Val Acc: 0.6354\n",
            "Laplace approximation fitted\n",
            "Iteration 11: Added 10 samples - Accuracy: 63.54%\n",
            "Laplace_Uncertainty Iteration 12/48\n",
            "Epoch 1/50 - Loss: 2.0331 - Acc: 0.3154 - Val Loss: 3.6933 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.1648 - Acc: 0.9385 - Val Loss: 1.4286 - Val Acc: 0.5960\n",
            "Epoch 50/50 - Loss: 0.0227 - Acc: 1.0000 - Val Loss: 1.7290 - Val Acc: 0.6316\n",
            "Laplace approximation fitted\n",
            "Iteration 12: Added 10 samples - Accuracy: 63.16%\n",
            "Laplace_Uncertainty Iteration 13/48\n",
            "Epoch 1/50 - Loss: 1.9591 - Acc: 0.3714 - Val Loss: 3.9762 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.0955 - Acc: 0.9571 - Val Loss: 1.5050 - Val Acc: 0.6354\n",
            "Epoch 50/50 - Loss: 0.0371 - Acc: 0.9929 - Val Loss: 1.6875 - Val Acc: 0.6435\n",
            "Laplace approximation fitted\n",
            "Iteration 13: Added 10 samples - Accuracy: 64.35%\n",
            "Laplace_Uncertainty Iteration 14/48\n",
            "Epoch 1/50 - Loss: 2.0978 - Acc: 0.3200 - Val Loss: 2.6913 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.0617 - Acc: 0.9867 - Val Loss: 1.4477 - Val Acc: 0.6383\n",
            "Epoch 50/50 - Loss: 0.0159 - Acc: 1.0000 - Val Loss: 2.1145 - Val Acc: 0.6219\n",
            "Laplace approximation fitted\n",
            "Iteration 14: Added 10 samples - Accuracy: 62.19%\n",
            "Laplace_Uncertainty Iteration 15/48\n",
            "Epoch 1/50 - Loss: 2.0014 - Acc: 0.2812 - Val Loss: 3.5180 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.1171 - Acc: 0.9563 - Val Loss: 1.4052 - Val Acc: 0.6535\n",
            "Epoch 50/50 - Loss: 0.0356 - Acc: 0.9875 - Val Loss: 1.7436 - Val Acc: 0.6498\n",
            "Laplace approximation fitted\n",
            "Iteration 15: Added 10 samples - Accuracy: 64.98%\n",
            "Laplace_Uncertainty Iteration 16/48\n",
            "Epoch 1/50 - Loss: 2.0934 - Acc: 0.2471 - Val Loss: 3.3135 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.0712 - Acc: 0.9824 - Val Loss: 1.7620 - Val Acc: 0.6024\n",
            "Epoch 50/50 - Loss: 0.0237 - Acc: 0.9882 - Val Loss: 2.2483 - Val Acc: 0.6066\n",
            "Laplace approximation fitted\n",
            "Iteration 16: Added 10 samples - Accuracy: 60.66%\n",
            "Laplace_Uncertainty Iteration 17/48\n",
            "Epoch 1/50 - Loss: 1.9676 - Acc: 0.3167 - Val Loss: 3.1088 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.0471 - Acc: 0.9944 - Val Loss: 1.7055 - Val Acc: 0.6136\n",
            "Epoch 50/50 - Loss: 0.0140 - Acc: 0.9944 - Val Loss: 2.1132 - Val Acc: 0.6397\n",
            "Laplace approximation fitted\n",
            "Iteration 17: Added 10 samples - Accuracy: 63.97%\n",
            "Laplace_Uncertainty Iteration 18/48\n",
            "Epoch 1/50 - Loss: 2.1062 - Acc: 0.2737 - Val Loss: 2.7509 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.1062 - Acc: 0.9684 - Val Loss: 1.3309 - Val Acc: 0.6812\n",
            "Epoch 50/50 - Loss: 0.0367 - Acc: 0.9947 - Val Loss: 1.6800 - Val Acc: 0.7025\n",
            "Laplace approximation fitted\n",
            "Iteration 18: Added 10 samples - Accuracy: 70.25%\n",
            "Laplace_Uncertainty Iteration 19/48\n",
            "Epoch 1/50 - Loss: 2.0656 - Acc: 0.3100 - Val Loss: 2.6170 - Val Acc: 0.1182\n",
            "Epoch 25/50 - Loss: 0.1251 - Acc: 0.9650 - Val Loss: 1.5118 - Val Acc: 0.6336\n",
            "Epoch 50/50 - Loss: 0.0396 - Acc: 0.9850 - Val Loss: 2.0588 - Val Acc: 0.6552\n",
            "Laplace approximation fitted\n",
            "Iteration 19: Added 10 samples - Accuracy: 65.52%\n",
            "Laplace_Uncertainty Iteration 20/48\n",
            "Epoch 1/50 - Loss: 1.9546 - Acc: 0.3476 - Val Loss: 3.8604 - Val Acc: 0.1029\n",
            "Epoch 25/50 - Loss: 0.0783 - Acc: 0.9762 - Val Loss: 1.6455 - Val Acc: 0.6434\n",
            "Epoch 50/50 - Loss: 0.0264 - Acc: 0.9905 - Val Loss: 2.2387 - Val Acc: 0.6583\n",
            "Laplace approximation fitted\n",
            "Iteration 20: Added 10 samples - Accuracy: 65.83%\n",
            "Laplace_Uncertainty Iteration 21/48\n",
            "Epoch 1/50 - Loss: 2.0149 - Acc: 0.3409 - Val Loss: 2.7966 - Val Acc: 0.1256\n",
            "Epoch 25/50 - Loss: 0.0545 - Acc: 0.9909 - Val Loss: 1.2888 - Val Acc: 0.7011\n",
            "Epoch 50/50 - Loss: 0.0341 - Acc: 0.9909 - Val Loss: 1.5019 - Val Acc: 0.7223\n",
            "Laplace approximation fitted\n",
            "Iteration 21: Added 10 samples - Accuracy: 72.23%\n",
            "Laplace_Uncertainty Iteration 22/48\n",
            "Epoch 1/50 - Loss: 2.0305 - Acc: 0.3130 - Val Loss: 2.5304 - Val Acc: 0.1028\n",
            "Epoch 25/50 - Loss: 0.1086 - Acc: 0.9609 - Val Loss: 1.3787 - Val Acc: 0.7031\n",
            "Epoch 50/50 - Loss: 0.0632 - Acc: 0.9739 - Val Loss: 1.7367 - Val Acc: 0.7244\n",
            "Laplace approximation fitted\n",
            "Iteration 22: Added 10 samples - Accuracy: 72.44%\n",
            "Laplace_Uncertainty Iteration 23/48\n",
            "Epoch 1/50 - Loss: 2.0094 - Acc: 0.2708 - Val Loss: 2.5744 - Val Acc: 0.1223\n",
            "Epoch 25/50 - Loss: 0.0536 - Acc: 0.9875 - Val Loss: 1.4515 - Val Acc: 0.7257\n",
            "Epoch 50/50 - Loss: 0.0276 - Acc: 0.9958 - Val Loss: 1.6877 - Val Acc: 0.7283\n",
            "Laplace approximation fitted\n",
            "Iteration 23: Added 10 samples - Accuracy: 72.83%\n",
            "Laplace_Uncertainty Iteration 24/48\n",
            "Epoch 1/50 - Loss: 2.0050 - Acc: 0.3160 - Val Loss: 2.6271 - Val Acc: 0.1693\n",
            "Epoch 25/50 - Loss: 0.1227 - Acc: 0.9600 - Val Loss: 1.3456 - Val Acc: 0.7046\n",
            "Epoch 50/50 - Loss: 0.0240 - Acc: 0.9920 - Val Loss: 1.3738 - Val Acc: 0.7442\n",
            "Laplace approximation fitted\n",
            "Iteration 24: Added 10 samples - Accuracy: 74.42%\n",
            "Laplace_Uncertainty Iteration 25/48\n",
            "Epoch 1/50 - Loss: 2.0311 - Acc: 0.2654 - Val Loss: 2.3379 - Val Acc: 0.1454\n",
            "Epoch 25/50 - Loss: 0.1019 - Acc: 0.9577 - Val Loss: 1.1359 - Val Acc: 0.7306\n",
            "Epoch 50/50 - Loss: 0.0251 - Acc: 0.9962 - Val Loss: 1.4744 - Val Acc: 0.7401\n",
            "Laplace approximation fitted\n",
            "Iteration 25: Added 10 samples - Accuracy: 74.01%\n",
            "Laplace_Uncertainty Iteration 26/48\n",
            "Epoch 1/50 - Loss: 2.0894 - Acc: 0.2519 - Val Loss: 2.4194 - Val Acc: 0.1281\n",
            "Epoch 25/50 - Loss: 0.0781 - Acc: 0.9704 - Val Loss: 1.3302 - Val Acc: 0.7196\n",
            "Epoch 50/50 - Loss: 0.0506 - Acc: 0.9778 - Val Loss: 1.6487 - Val Acc: 0.7179\n",
            "Laplace approximation fitted\n",
            "Iteration 26: Added 10 samples - Accuracy: 71.79%\n",
            "Laplace_Uncertainty Iteration 27/48\n",
            "Epoch 1/50 - Loss: 1.9923 - Acc: 0.3036 - Val Loss: 2.4898 - Val Acc: 0.1028\n",
            "Epoch 25/50 - Loss: 0.0812 - Acc: 0.9821 - Val Loss: 1.4022 - Val Acc: 0.7237\n",
            "Epoch 50/50 - Loss: 0.0140 - Acc: 1.0000 - Val Loss: 1.6138 - Val Acc: 0.7246\n",
            "Laplace approximation fitted\n",
            "Iteration 27: Added 10 samples - Accuracy: 72.46%\n",
            "Laplace_Uncertainty Iteration 28/48\n",
            "Epoch 1/50 - Loss: 1.9790 - Acc: 0.3069 - Val Loss: 2.5088 - Val Acc: 0.1545\n",
            "Epoch 25/50 - Loss: 0.0609 - Acc: 0.9793 - Val Loss: 1.2728 - Val Acc: 0.7314\n",
            "Epoch 50/50 - Loss: 0.0444 - Acc: 0.9897 - Val Loss: 1.3943 - Val Acc: 0.7501\n",
            "Laplace approximation fitted\n",
            "Iteration 28: Added 10 samples - Accuracy: 75.01%\n",
            "Laplace_Uncertainty Iteration 29/48\n",
            "Epoch 1/50 - Loss: 2.0146 - Acc: 0.2867 - Val Loss: 2.2731 - Val Acc: 0.1552\n",
            "Epoch 25/50 - Loss: 0.0760 - Acc: 0.9633 - Val Loss: 1.1064 - Val Acc: 0.7593\n",
            "Epoch 50/50 - Loss: 0.0281 - Acc: 0.9933 - Val Loss: 1.4002 - Val Acc: 0.7560\n",
            "Laplace approximation fitted\n",
            "Iteration 29: Added 10 samples - Accuracy: 75.60%\n",
            "Laplace_Uncertainty Iteration 30/48\n",
            "Epoch 1/50 - Loss: 1.9944 - Acc: 0.3194 - Val Loss: 2.3881 - Val Acc: 0.1571\n",
            "Epoch 25/50 - Loss: 0.0518 - Acc: 0.9710 - Val Loss: 0.9766 - Val Acc: 0.7837\n",
            "Epoch 50/50 - Loss: 0.0303 - Acc: 0.9903 - Val Loss: 1.0883 - Val Acc: 0.7924\n",
            "Laplace approximation fitted\n",
            "Iteration 30: Added 10 samples - Accuracy: 79.24%\n",
            "Laplace_Uncertainty Iteration 31/48\n",
            "Epoch 1/50 - Loss: 2.0804 - Acc: 0.3031 - Val Loss: 2.3392 - Val Acc: 0.1009\n",
            "Epoch 25/50 - Loss: 0.0528 - Acc: 0.9906 - Val Loss: 0.7783 - Val Acc: 0.8145\n",
            "Epoch 50/50 - Loss: 0.0313 - Acc: 0.9875 - Val Loss: 0.9007 - Val Acc: 0.8267\n",
            "Laplace approximation fitted\n",
            "Iteration 31: Added 10 samples - Accuracy: 82.67%\n",
            "Laplace_Uncertainty Iteration 32/48\n",
            "Epoch 1/50 - Loss: 2.0364 - Acc: 0.2939 - Val Loss: 2.3402 - Val Acc: 0.1317\n",
            "Epoch 25/50 - Loss: 0.0596 - Acc: 0.9788 - Val Loss: 0.5869 - Val Acc: 0.8485\n",
            "Epoch 50/50 - Loss: 0.0053 - Acc: 1.0000 - Val Loss: 0.7489 - Val Acc: 0.8499\n",
            "Laplace approximation fitted\n",
            "Iteration 32: Added 10 samples - Accuracy: 84.99%\n",
            "Laplace_Uncertainty Iteration 33/48\n",
            "Epoch 1/50 - Loss: 2.0013 - Acc: 0.2647 - Val Loss: 2.4218 - Val Acc: 0.1737\n",
            "Epoch 25/50 - Loss: 0.0594 - Acc: 0.9794 - Val Loss: 0.7269 - Val Acc: 0.8300\n",
            "Epoch 50/50 - Loss: 0.0400 - Acc: 0.9941 - Val Loss: 0.7042 - Val Acc: 0.8471\n",
            "Laplace approximation fitted\n",
            "Iteration 33: Added 10 samples - Accuracy: 84.71%\n",
            "Laplace_Uncertainty Iteration 34/48\n",
            "Epoch 1/50 - Loss: 2.0033 - Acc: 0.2829 - Val Loss: 2.3070 - Val Acc: 0.1771\n",
            "Epoch 25/50 - Loss: 0.0570 - Acc: 0.9857 - Val Loss: 0.5778 - Val Acc: 0.8523\n",
            "Epoch 50/50 - Loss: 0.0271 - Acc: 0.9971 - Val Loss: 0.7177 - Val Acc: 0.8546\n",
            "Laplace approximation fitted\n",
            "Iteration 34: Added 10 samples - Accuracy: 85.46%\n",
            "Laplace_Uncertainty Iteration 35/48\n",
            "Epoch 1/50 - Loss: 1.9616 - Acc: 0.2972 - Val Loss: 2.4677 - Val Acc: 0.1824\n",
            "Epoch 25/50 - Loss: 0.0352 - Acc: 0.9944 - Val Loss: 0.6828 - Val Acc: 0.8435\n",
            "Epoch 50/50 - Loss: 0.0243 - Acc: 0.9861 - Val Loss: 0.7668 - Val Acc: 0.8447\n",
            "Laplace approximation fitted\n",
            "Iteration 35: Added 10 samples - Accuracy: 84.47%\n",
            "Laplace_Uncertainty Iteration 36/48\n",
            "Epoch 1/50 - Loss: 1.9875 - Acc: 0.3270 - Val Loss: 2.4070 - Val Acc: 0.1712\n",
            "Epoch 25/50 - Loss: 0.0615 - Acc: 0.9784 - Val Loss: 0.6813 - Val Acc: 0.8226\n",
            "Epoch 50/50 - Loss: 0.0261 - Acc: 0.9946 - Val Loss: 0.6752 - Val Acc: 0.8573\n",
            "Laplace approximation fitted\n",
            "Iteration 36: Added 10 samples - Accuracy: 85.73%\n",
            "Laplace_Uncertainty Iteration 37/48\n",
            "Epoch 1/50 - Loss: 1.9607 - Acc: 0.3553 - Val Loss: 2.3261 - Val Acc: 0.1516\n",
            "Epoch 25/50 - Loss: 0.0688 - Acc: 0.9763 - Val Loss: 0.6515 - Val Acc: 0.8445\n",
            "Epoch 50/50 - Loss: 0.0145 - Acc: 0.9974 - Val Loss: 0.8758 - Val Acc: 0.8425\n",
            "Laplace approximation fitted\n",
            "Iteration 37: Added 10 samples - Accuracy: 84.25%\n",
            "Laplace_Uncertainty Iteration 38/48\n",
            "Epoch 1/50 - Loss: 1.9912 - Acc: 0.3385 - Val Loss: 2.2366 - Val Acc: 0.2166\n",
            "Epoch 25/50 - Loss: 0.0969 - Acc: 0.9615 - Val Loss: 0.4656 - Val Acc: 0.8652\n",
            "Epoch 50/50 - Loss: 0.0086 - Acc: 0.9974 - Val Loss: 0.6309 - Val Acc: 0.8682\n",
            "Laplace approximation fitted\n",
            "Iteration 38: Added 10 samples - Accuracy: 86.82%\n",
            "Laplace_Uncertainty Iteration 39/48\n",
            "Epoch 1/50 - Loss: 2.0241 - Acc: 0.2800 - Val Loss: 2.3924 - Val Acc: 0.1643\n",
            "Epoch 25/50 - Loss: 0.0856 - Acc: 0.9725 - Val Loss: 0.5091 - Val Acc: 0.8633\n",
            "Epoch 50/50 - Loss: 0.0198 - Acc: 0.9975 - Val Loss: 0.5462 - Val Acc: 0.8873\n",
            "Laplace approximation fitted\n",
            "Iteration 39: Added 10 samples - Accuracy: 88.73%\n",
            "Laplace_Uncertainty Iteration 40/48\n",
            "Epoch 1/50 - Loss: 1.9202 - Acc: 0.3073 - Val Loss: 2.4406 - Val Acc: 0.1425\n",
            "Epoch 25/50 - Loss: 0.0460 - Acc: 0.9878 - Val Loss: 0.4447 - Val Acc: 0.8848\n",
            "Epoch 50/50 - Loss: 0.0323 - Acc: 0.9951 - Val Loss: 0.4474 - Val Acc: 0.9000\n",
            "Laplace approximation fitted\n",
            "Iteration 40: Added 10 samples - Accuracy: 90.00%\n",
            "Laplace_Uncertainty Iteration 41/48\n",
            "Epoch 1/50 - Loss: 1.9332 - Acc: 0.3167 - Val Loss: 2.3257 - Val Acc: 0.1810\n",
            "Epoch 25/50 - Loss: 0.0566 - Acc: 0.9833 - Val Loss: 0.5262 - Val Acc: 0.8699\n",
            "Epoch 50/50 - Loss: 0.0242 - Acc: 0.9881 - Val Loss: 0.5637 - Val Acc: 0.8884\n",
            "Laplace approximation fitted\n",
            "Iteration 41: Added 10 samples - Accuracy: 88.84%\n",
            "Laplace_Uncertainty Iteration 42/48\n",
            "Epoch 1/50 - Loss: 1.9612 - Acc: 0.3047 - Val Loss: 2.3772 - Val Acc: 0.1763\n",
            "Epoch 25/50 - Loss: 0.0473 - Acc: 0.9767 - Val Loss: 0.4836 - Val Acc: 0.8828\n",
            "Epoch 50/50 - Loss: 0.0198 - Acc: 0.9907 - Val Loss: 0.5551 - Val Acc: 0.8843\n",
            "Laplace approximation fitted\n",
            "Iteration 42: Added 10 samples - Accuracy: 88.43%\n",
            "Laplace_Uncertainty Iteration 43/48\n",
            "Epoch 1/50 - Loss: 1.9478 - Acc: 0.3295 - Val Loss: 2.2647 - Val Acc: 0.1986\n",
            "Epoch 25/50 - Loss: 0.0423 - Acc: 0.9818 - Val Loss: 0.4759 - Val Acc: 0.8705\n",
            "Epoch 50/50 - Loss: 0.0301 - Acc: 0.9864 - Val Loss: 0.5933 - Val Acc: 0.8712\n",
            "Laplace approximation fitted\n",
            "Iteration 43: Added 10 samples - Accuracy: 87.12%\n",
            "Laplace_Uncertainty Iteration 44/48\n",
            "Epoch 1/50 - Loss: 1.9658 - Acc: 0.3267 - Val Loss: 2.3100 - Val Acc: 0.1787\n",
            "Epoch 25/50 - Loss: 0.0818 - Acc: 0.9800 - Val Loss: 0.4564 - Val Acc: 0.8720\n",
            "Epoch 50/50 - Loss: 0.0331 - Acc: 0.9889 - Val Loss: 0.5425 - Val Acc: 0.8862\n",
            "Laplace approximation fitted\n",
            "Iteration 44: Added 10 samples - Accuracy: 88.62%\n",
            "Laplace_Uncertainty Iteration 45/48\n",
            "Epoch 1/50 - Loss: 2.0218 - Acc: 0.2891 - Val Loss: 2.5218 - Val Acc: 0.1318\n",
            "Epoch 25/50 - Loss: 0.0575 - Acc: 0.9783 - Val Loss: 0.4029 - Val Acc: 0.8935\n",
            "Epoch 50/50 - Loss: 0.0216 - Acc: 0.9913 - Val Loss: 0.4690 - Val Acc: 0.8980\n",
            "Laplace approximation fitted\n",
            "Iteration 45: Added 10 samples - Accuracy: 89.80%\n",
            "Laplace_Uncertainty Iteration 46/48\n",
            "Epoch 1/50 - Loss: 1.8982 - Acc: 0.3426 - Val Loss: 2.4323 - Val Acc: 0.1880\n",
            "Epoch 25/50 - Loss: 0.0589 - Acc: 0.9830 - Val Loss: 0.3413 - Val Acc: 0.9136\n",
            "Epoch 50/50 - Loss: 0.0203 - Acc: 0.9936 - Val Loss: 0.4115 - Val Acc: 0.9141\n",
            "Laplace approximation fitted\n",
            "Iteration 46: Added 10 samples - Accuracy: 91.41%\n",
            "Laplace_Uncertainty Iteration 47/48\n",
            "Epoch 1/50 - Loss: 2.0027 - Acc: 0.3354 - Val Loss: 2.2516 - Val Acc: 0.1894\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-176e7b56aa60>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run Active Learning on Laplace Uncertainty Acquisition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m accuracies_l, added_indices_l = Active_learning(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0macquisition_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"laplace_uncertainty\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_samples_per_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/main.py\u001b[0m in \u001b[0;36mActive_learning\u001b[0;34m(acquisition_type, initial_n_samples, n_samples_per_iter, n_total_samples, n_epochs, batch_size, use_wandb, mc_iterations)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# Acquisition strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Colab Notebooks/model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, model_dir)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Run Active Learning on Laplace Uncertainty Acquisition\n",
        "accuracies_l, added_indices_l = Active_learning(\n",
        "    acquisition_type=\"laplace_uncertainty\",\n",
        "    n_epochs=50,\n",
        "    n_samples_per_iter=10,\n",
        "    initial_n_samples=20,\n",
        "    n_total_samples=500,\n",
        "    use_wandb=False\n",
        ")\n",
        "\n",
        "# Run Active Learning on Random Acquisition\n",
        "accuracies_r, added_indices_r = Active_learning(\n",
        "    acquisition_type=\"random\",\n",
        "    n_epochs=50,\n",
        "    n_samples_per_iter=10,\n",
        "    initial_n_samples=20,\n",
        "    n_total_samples=500,\n",
        "    use_wandb=False\n",
        ")\n",
        "\n",
        "# Run Active Learning on Knowlege Uncertainty Acquisition\n",
        "accuracies_k, added_indices_k = Active_learning(\n",
        "   acquisition_type=\"knowledge_uncertainty\",\n",
        "    n_epochs=50,\n",
        "    n_samples_per_iter=10,\n",
        "    initial_n_samples=20,\n",
        "    n_total_samples=500,\n",
        "    use_wandb=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXaAAe5R0Opy"
      },
      "source": [
        "### 2.5  Visualise the Results\n",
        "\n",
        "Now that we have our loop, we can inspect the results of this\n",
        "process. We will use seaborn and matplotlib to visualize our\n",
        "results. The main result we are interested in is the test accuracy over time\n",
        "for both the models trained with a random acquisition function and\n",
        "the models trained with data acquired via knowledge uncertainty.\n",
        "To visualize this, we define `ActiveLearningVisualizer` that loads the results and\n",
        "then returns a plot that shows the accuracy per active learning\n",
        "iteration cycle.\n",
        "\n",
        "We can then use this function to plot the results for all acquisition\n",
        "functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIDK-GgxBBFH"
      },
      "outputs": [],
      "source": [
        "from visualise import ActiveLearningVisualizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize visualizer\n",
        "visualizer = ActiveLearningVisualizer(output_dir=\"output\", samples_per_iter=10, initial_samples=20)\n",
        "\n",
        "# Compare different acquisition strategies\n",
        "# IMPORTANT: change the uuids according to the ones assigned to each of the models trained\n",
        "fig_acc, fig_img, imgs = visualizer.compare_from_uuids(\n",
        "    uuids=[\"f495ac8f-2dd6-45f4-8142-5ac2d4c0ddb4\",\n",
        "            \"3431804b-e582-48ba-a8e2-872c87c63146\",\n",
        "            \"2dcb6f4f-495e-4b5c-b50c-03daedcd1ef2\"],\n",
        "    acquisition_types=[\"laplace_uncertainty\", \"random\", \"knowledge_uncertainty\"]\n",
        ")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-QJAhQhOX2L"
      },
      "source": [
        "**Question 5 (10 marks)**\n",
        "\n",
        "- What can you conclude from the figure that shows the Accuracy of the different acquisition strategies? (**5 marks**). Use a single sentence.\n",
        "\n",
        "*Solution*\n",
        "\n",
        "Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What can you conclude when comparing the samples of the digits chosen for training by the different Acquisition strategies? (**5 marks**). Use a single sentence.\n",
        "\n",
        "*Solution*\n",
        "\n",
        "Write your answer here"
      ],
      "metadata": {
        "id": "7fLnXe1gYgrE"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd9dae3481994b1d98e387cae7eb21d5": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_921e79d9985342dfa2a269deb03c25db",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   3000    0             1.52        1            2555.38 draws/s   0:00:01   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   3000    0             1.23        1            1384.29 draws/s   0:00:02   0:00:00    \n                                                                                                                   \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                 </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed  </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             1.52        1            2555.38 draws/s   0:00:01   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             1.23        1            1384.29 draws/s   0:00:02   0:00:00    \n                                                                                                                   \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "921e79d9985342dfa2a269deb03c25db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0586938686004dd4ac9f6778d7135c78": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9639fef5045a438eace08079546af5b3",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "                                                                                                                   \n \u001b[1m \u001b[0m\u001b[1mProgress                 \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDraws\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDivergences\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mStep size\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mGrad evals\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mSampling Speed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mElapsed\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mRemaining\u001b[0m\u001b[1m \u001b[0m \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   3000    0             0.77        7            819.48 draws/s   0:00:03   0:00:00    \n  \u001b[38;2;31;119;180m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   3000    0             0.69        7            418.62 draws/s   0:00:07   0:00:00    \n                                                                                                                   \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                                                   \n <span style=\"font-weight: bold\"> Progress                  </span> <span style=\"font-weight: bold\"> Draws </span> <span style=\"font-weight: bold\"> Divergences </span> <span style=\"font-weight: bold\"> Step size </span> <span style=\"font-weight: bold\"> Grad evals </span> <span style=\"font-weight: bold\"> Sampling Speed </span> <span style=\"font-weight: bold\"> Elapsed </span> <span style=\"font-weight: bold\"> Remaining </span> \n ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             0.77        7            819.48 draws/s   0:00:03   0:00:00    \n  <span style=\"color: #1f77b4; text-decoration-color: #1f77b4\">━━━━━━━━━━━━━━━━━━━━━━━━━</span>   3000    0             0.69        7            418.62 draws/s   0:00:07   0:00:00    \n                                                                                                                   \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "9639fef5045a438eace08079546af5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}