{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushpatra11/RLU_UoM/blob/main/COM64102_Assignment_a85716ap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf52PGSevKXY"
      },
      "source": [
        "# Assignment Brief: Probabilistic Programming and Active Learning\n",
        "\n",
        "## Deadline: May 7, 2025, 17:00 GMT\n",
        "\n",
        "## Number of marks available: 50\n",
        "\n",
        "This coursework is made of two parts. In the first part, you will use probabilistic programming to perform Bayesian inference in different models. In the second part, you will use uncertainty to guide datapoint selection to create a dataset to train a machine learning model.\n",
        "\n",
        "### Please READ the whole assignment first, before starting to work on it.\n",
        "\n",
        "### How and what to submit\n",
        "\n",
        "A. A **Jupyter Notebook** with the code in all the cells executed and outputs displayed.\n",
        "\n",
        "B. Name your Notebook **COM64102_Assignment_XXXXXX.ipynb** where XXXXXX is your username such as such as abc18de. Example: `COM64102_Assignment_abc18de.ipynb`\n",
        "\n",
        "C. Upload the Jupyter Notebook in B to Blackboard under the submission area before the deadline.\n",
        "\n",
        "D. **NO DATA UPLOAD**: Please do not upload the data files used in this Notebook. We have a copy already.\n",
        "\n",
        "\n",
        "### Assessment Criteria\n",
        "\n",
        "* Being able to compute the posterior distribution in Bayesian logistic regression using a probabilistic program.\n",
        "\n",
        "* Being able to compute several acquisition functions useful for active learning.\n",
        "\n",
        "* Being able to use active learning to speed-up the training process of a digit classifier.\n",
        "\n",
        "\n",
        "### Code quality and use of Python libraries\n",
        "When writing your code, you will find out that there are operations that are repeated at least twice. If your code is unreadable, we may not award marks for that section. Make sure to check the following:\n",
        "\n",
        "* Did you include Python functions to solve the question and avoid repeating code?\n",
        "* Did you comment your code to make it readable to others?\n",
        "\n",
        "### Late submissions\n",
        "\n",
        "We follow Department's guidelines about late submissions, i.e., a deduction of 10% of the mark each 24 hours the work is late after the deadline. NO late submission will be marked one week after the deadline.\n",
        "\n",
        "### Use of unfair means\n",
        "\n",
        "**Any form of unfair means is treated as a serious academic offence and action may be taken under the Discipline Regulations.** Please carefully read [what constitutes Unfair Means](https://documents.manchester.ac.uk/display.aspx?DocID=2870) if not sure. If you still have questions, please ask your Personal tutor or the Lecturers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjSTJn07PvUe"
      },
      "source": [
        "# 1. Probabilistic Programming with PyMC\n",
        "\n",
        "[PyMC](https://www.pymc.io/) is a powerful Python library for **Bayesian statistical modeling** and **probabilistic machine learning**. It provides an intuitive and flexible way to define complex models using a **probabilistic programming framework**.\n",
        "\n",
        "PyMC makes it easy to express statistical models in terms of probability distributions, and it automates the process of computing posterior distributions using state-of-the-art Markov Chain Monte Carlo (MCMC) sampling methods like:\n",
        "- [**No-U-Turn Sampler (NUTS)**](https://jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf), an efficient Hamiltonian Monte Carlo method.\n",
        "- **Metropolis-Hastings** ‚Äö a traditional and widely-used MCMC approach.\n",
        "\n",
        "Bayesian inference involves calculating the posterior distribution:\n",
        "$$\n",
        "P(\\theta | X) \\propto P(X | \\theta)P(\\theta)\n",
        "$$\n",
        "where:\n",
        "- $P(\\theta)$‚Äö a prior distribution (our prior belief about the parameters).\n",
        "- $P(X | \\theta)$‚Äö a likelihood of the data given the parameters.\n",
        "- $P(\\theta | X)$, a posterior distribution (what we want to estimate).\n",
        "\n",
        "Computing this posterior distribution analytically can be difficult or even impossible for complex models. PyMC solves this problem by using efficient numerical sampling techniques, allowing you to approximate the posterior distribution and extract meaningful insights.\n",
        "\n",
        "## How Does PyMC Work?\n",
        "1. **Model Definition**: Define the model using PyMC probabilistic building blocks (e.g., `pm.Normal`, `pm.Bernoulli`).\n",
        "2. **Sampling**: Use `pm.sample()` to draw samples from the posterior distribution.\n",
        "3. **Posterior Analysis**: Analyze the posterior samples to estimate parameters, uncertainties, and credible intervals.\n",
        "\n",
        "PyMC builds on [**Theano**](https://en.wikipedia.org/wiki/Theano_(software)), which allows it to compute gradients and perform symbolic differentiation for more efficient sampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYaNqYbrPvUf"
      },
      "source": [
        "## 1.1 Bayesian inference over the mean of a Gaussian using PyMC\n",
        "\n",
        "In [Lab 1 for this module](https://colab.research.google.com/github/m-caprio/COMP64102-Reasoning-and-Learning-under-Uncertainty-Module/blob/main/New%20Lab%201.ipynb), you computed the posterior distribution over the mean of a Gaussian distribution in closed form using the fact that the Gaussian likelihood and the prior over the mean of the Gaussian likelihood are conjugate. The equation for the mean of the posterior distribution had a closed form.\n",
        "\n",
        "As a warm up example in the use of PyMC, we will do the same example using the probabilistic programming language. Refer to [Lab 1](https://colab.research.google.com/github/m-caprio/COMP64102-Reasoning-and-Learning-under-Uncertainty-Module/blob/main/New%20Lab%201.ipynb) when reading forward.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlpRhM9bPvUf"
      },
      "source": [
        "Besides installing PyMC, we will also install the [ArViz](https://python.arviz.org/en/stable/) package, which is used for exploratory analysis of Bayesian models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ImVOIHTEPvUf"
      },
      "outputs": [],
      "source": [
        "!pip install pymc\n",
        "import pymc as pm\n",
        "import arviz as az"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGZf0OPJRKM4"
      },
      "source": [
        "The following code uses PyMC to obtain samples from the posterior distribution of the mean of the Gaussian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEYvCd_4RkYy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Observed data (assumed to be generated from a Gaussian distribution)\n",
        "data = np.array([3.2, 2.8, 3.6, 3.0, 3.1, 2.9, 3.3, 3.5])\n",
        "\n",
        "# Known standard deviation of the data\n",
        "sigma = 0.5\n",
        "\n",
        "# Define the model in PyMC\n",
        "with pm.Model() as model:\n",
        "    # Prior for mu (mean) - assume Gaussian prior\n",
        "    mu_0 = 3.0  # Prior mean\n",
        "    sigma_0 = 1.0  # Prior standard deviation\n",
        "    mu = pm.Normal('mu', mu=mu_0, sigma=sigma_0) # Prior\n",
        "\n",
        "    # Likelihood for the data - assume Gaussian likelihood\n",
        "    likelihood = pm.Normal('likelihood', mu=mu, sigma=sigma, observed=data) # Likelihood\n",
        "\n",
        "    # Sample from the posterior distribution\n",
        "    trace = pm.sample(2000, return_inferencedata=True)\n",
        "\n",
        "# Extract posterior samples\n",
        "mu_p_samples = trace.posterior['mu'].values.flatten()\n",
        "\n",
        "# Compute posterior mean and standard deviation\n",
        "mu_p = np.mean(mu_p_samples)\n",
        "sigma_p = np.std(mu_p_samples)\n",
        "\n",
        "# Print results\n",
        "print(f\"Posterior mean (mu_p): {mu_p:.2f}\")\n",
        "print(f\"Posterior standard deviation (sigma_p): {sigma_p:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrVPs2LsTKyh"
      },
      "source": [
        "The values for the posterior mean and posterior standard deviation when comparing the exact solution in Lab 1 and the sampling approach using PyMC are the same.\n",
        "\n",
        "**Question 1 (5 marks)**\n",
        "\n",
        "What is the fundamental difference between the approach to compute the mean of the posterior distribution in Lab 1 and the approach to compute the mean using PyMC.\n",
        "\n",
        "*Solution*\n",
        "\n",
        "Write our answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YmKGYopu7UX"
      },
      "source": [
        "We can now plot the prior, likelihood and the posterior pdf's."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHuuvveMvBTI"
      },
      "outputs": [],
      "source": [
        "# Plot prior, likelihood, and posterior\n",
        "x = np.linspace(2, 4, 1000)  # Range of mu values to plot\n",
        "prior = norm.pdf(x, mu_0, sigma_0)  # Prior distribution\n",
        "likelihood = norm.pdf(x, np.mean(data), sigma / np.sqrt(len(data)))  # Likelihood\n",
        "posterior = norm.pdf(x, mu_p, sigma_p)  # Posterior distribution\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, prior, label=\"Prior\", linestyle=\"--\")\n",
        "plt.plot(x, likelihood, label=\"Likelihood\", linestyle=\"-.\")\n",
        "plt.plot(x, posterior, label=\"Posterior\", linestyle=\"-\")\n",
        "plt.title(\"Bayesian Update of Gaussian Mean (PyMC)\")\n",
        "plt.xlabel(\"Mean ($\\mu$)\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmkimtfdxGEf"
      },
      "source": [
        "Two metrics to assess convergence in MCMC are the **effective sample size** (ESS) and the **estimated potential scale reduction** (EPSRC) or **R-hat**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUbtE6o-x057"
      },
      "source": [
        "We can use the [ArViz](https://python.arviz.org/en/stable/) package to compute both quantities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM4wgfNkyAmt"
      },
      "outputs": [],
      "source": [
        "# Posterior summary (for more detailed diagnostics)\n",
        "print(az.summary(trace, var_names=[\"mu\"], hdi_prob=0.95))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iugJGyZo0JNX"
      },
      "source": [
        "**Question 2 (5 marks)**\n",
        "\n",
        "The value of `r_hat` for the mean is equal to 1.0. Explain what `r_hat` computes and whether 1.0 is a good value. Explain why it is or why it is not a good value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn-MMjNi1JRB"
      },
      "source": [
        "*Solution*\n",
        "\n",
        "Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaUjD0aM5Jhj"
      },
      "source": [
        "## 1.2 Bayesian logistic regression with PyMC\n",
        "\n",
        "In the previous module in Foundations of Machine Learning, we spent some time on a linear model for classification called **logistic regression**.\n",
        "\n",
        "In a binary classification problem, let $\\mathbf{X}=[\\mathbf{x}_1 \\cdots \\mathbf{x}_N]^\\top$ and and $\\mathbf{y} =[y_1\\cdots y_N]^{\\top}$, where $\\mathbf{X}$ is the design matrix and each element in $\\mathbf{y}$, say $y_n$ indicates to which class the corresponding input vector, $\\mathbf{x}_n$, belongs to.\n",
        "\n",
        "Assumming IID observations, the likelihood for the dataset is given as\n",
        "\\begin{align*}\n",
        "p(\\mathbf{y}|\\mathbf{w},\\mathbf{X}) = \\prod_{n=1}^Np(y_n|\\mathbf{w},\\mathbf{x}_n)\n",
        "  =\\prod_{n=1}^N\\textrm{Ber}(y_n|\\sigma(\\mathbf{w}^{\\top}\\mathbf{x}_n)),\n",
        "\\end{align*}\n",
        "where $\\textrm{Ber}(y_n|\\mu)$ refers to the Bernoulli distribution with parameter $\\mu$, and $\\sigma(a)$ is the sigmoid function defined as $\\sigma(a)=\\frac{1}{1+ \\exp(-a)}$.\n",
        "\n",
        "The maximum-likelihood estimator for $\\mathbf{w}$ can be obtained by minimising the negative log-likelihood (or the cross-entropy function) given as\n",
        "\n",
        "\\begin{align*}\n",
        "NLL(\\mathbf{w}) & = - \\log p(\\mathbf{y}|\\mathbf{w},\\mathbf{X}) \\\\\n",
        "& = - \\sum_{n=1}^N\\{y_n\\log[\\sigma(\\mathbf{w}^{\\top}\\mathbf{x}_n)] + (1-y_n)\\log[1 - \\sigma(\\mathbf{w}^{\\top}\\mathbf{x}_n)] \\}.\n",
        "\\end{align*}\n",
        "\n",
        "In *Bayesian logistic regression*, we put a prior over the weights $\\mathbf{w}$. We then compute the posterior distribution\n",
        "\\begin{align*}\n",
        "p(\\mathbf{w}|\\mathbf{X}, \\mathbf{y}) \\propto p(\\mathbf{y}|\\mathbf{w}, \\mathbf{X})p(\\mathbf{w}).\n",
        "\\end{align*}\n",
        "For predicting the class of a text point, $\\mathbf{x}_*$, we need to compute the predictive distribution,\n",
        "\\begin{align}\n",
        "p(y_*|\\mathbf{x}_*)=\\int \\sigma(\\mathbf{w}^{\\top}\\mathbf{x}_*)p(\\mathbf{w}|\\mathbf{X}, \\mathbf{y})d\\mathbf{w}.\n",
        "\\end{align}\n",
        "\n",
        "If we approximate the posterior distribution $p(\\mathbf{w}|\\mathbf{X}, \\mathbf{y})$ with a Gaussian posterior distribution,\n",
        "\\begin{align*}\n",
        "p(\\mathbf{w}|\\mathbf{X}, \\mathbf{y}) ‚âà q(\\mathbf{w}|\\mathbf{X}, \\mathbf{y}) = N(\\mathbf{w}|ùõç_{\\text{post}}, ùö∫_{\\text{post}}),\n",
        "\\end{align*}\n",
        "it can be shown the predictive distribution can also be approximated as\n",
        "\\begin{align*}\n",
        "p(y_*=1|\\mathbf{x}_*) = \\sigma(\\kappa (\\sigma^2_a)\\mu_a),\n",
        "\\end{align*}\n",
        "where\n",
        "\\begin{align*}\n",
        "\\mu_a &= ùõç_{\\text{post}}^\\top\\mathbf{x}_*,\\\\\n",
        "\\sigma_a^2 &= \\mathbf{x}^\\top_*ùö∫_{\\text{post}}\\mathbf{x}_*,\\\\\n",
        "\\kappa(\\sigma^2) &= \\frac{1}{(1+\\pi \\sigma^2/8)^{\\frac{1}{2}}}\n",
        "\\end{align*}\n",
        "\n",
        "\n",
        "### Bayesian logistic regression for the Iris dataset\n",
        "\n",
        "To illustrate how Bayesian logistic regression works, we will use a very well known dataset, the [Iris dataset](https://archive.ics.uci.edu/dataset/53/iris). The dataset has three classes and four input features. We will only use two classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukNbfo9zvDNN"
      },
      "source": [
        "Let us load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdETdAXgvFTW"
      },
      "outputs": [],
      "source": [
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "iris = fetch_ucirepo(id=53)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X3 = iris.data.features\n",
        "y3 = iris.data.targets\n",
        "# Drop the last class and the last two columns\n",
        "Xp = X3.drop(X3.index[100:150])\n",
        "yp = y3.drop(y3.index[100:150])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt3Ncv8jynbB"
      },
      "source": [
        "We now have a reduced dataset that we will split into training and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhZDzlvIvdAe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "# We add a vector of ones to the input space in X\n",
        "X = Xp.to_numpy()\n",
        "# Add a column of ones to X\n",
        "y = np.vstack((np.zeros((50, 1)), np.ones((50, 1))))\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=int(1e3))\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2AWsxxNzs0y"
      },
      "source": [
        "**Question 3 (10 marks)**\n",
        "\n",
        "Let us define the following prior distribution for $\\mathbf{w}$, $p(\\mathbf{w})= N(\\mathbf{w}|\\mathbf{0}_4, 0.001\\times \\mathbf{I}_4)$, where $\\mathbf{0}_4 = [0, 0, 0, 0]^\\top$ and $\\mathbf{I}_4$ is the identity matrix of dimension four since there are four input features.\n",
        "\n",
        "Using the training data `X_train` and `y_train`, compute an approximate posterior Gaussian distribution using PyMC for a Bayesian logistic regression model. Use 2000 samples for the sampler and report the mean and the covariance matrix for the approximate Gaussian using the last 1000 samples of one of the chains (**7 marks**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL67G-rT11O6"
      },
      "source": [
        "*Solution*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H23KT6fe1y21"
      },
      "outputs": [],
      "source": [
        "# Write your code here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-NGzSdwm1NP"
      },
      "source": [
        "Compute the accuracy of the linear classifier over the test set using the approximated distribution $p(y_*=1|\\mathbf{x}_*) = \\sigma(\\kappa (\\sigma^2_a)\\mu_a)$, as explained above (**3 marks**)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Solution*"
      ],
      "metadata": {
        "id": "IiTVWabFXZgm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWzhzUPRkwY9"
      },
      "outputs": [],
      "source": [
        "# Write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWKwKL2QVO4Z"
      },
      "source": [
        "# 2. Active Learning -- Using data selection via uncertainty to keep models fresh\n",
        "\n",
        "We can use\n",
        "uncertainties to figure out whether data should be part of the training data\n",
        "or not. We can expand on this idea in the context of an area of\n",
        "machine learning called **active learning**. The promise of active\n",
        "learning is that a model can learn more eÔ¨Äectively on less data if we\n",
        "have a way to control the type of data it is trained on. Active learning is a way to\n",
        "guide the learning process and data a model is trained on by\n",
        "**providing acquisition functions** that can acquire data from a pool of data that is\n",
        "not part of the training data. By iteratively selecting the right data\n",
        "from the pool, we can train a model that performs better than if we\n",
        "had chosen the data from the pool at random.\n",
        "\n",
        "The active learning approach can be described with the following iterative procedure\n",
        "```\n",
        "A model is initially trained using a few samples per class\n",
        "for iter until a fixed number of iterations:\n",
        "  compute an acquisition function over the data in the pool\n",
        "  based on the acquisition function select a sample to include in the  \n",
        "     training data\n",
        "  train the model again using the augmented training data\n",
        "```\n",
        "\n",
        "In this part of the coursework, we will use results from a fundamental\n",
        "active learning paper: [Deep Bayesian Active Learning with Image Data\n",
        "(2017)](https://arxiv.org/abs/1703.02910). We will use the MNIST dataset and train a model on more\n",
        "and more data, where we select the data points to add to our\n",
        "training set via an uncertainty method. In this case, we will use **epistemic uncertainty** to select the most informative data points.\n",
        "Images with high epistemic uncertainty will be added to the traininig dataset in a sequential manner. The epistemic uncertainty can be computed using different methods. You will use **Monte Carlo dropout** and will compare the performance of using epistemic uncertainty to introduce new points in the training data against including new training points just but randomly selecting from a pool of available data.\n",
        "\n",
        "**IMPORTANT** To reduce the amount of code appearing in the notebook, we have created a set of python modules that include auxiliary functions. You need to make sure when running the notebook that your Google Drive is mounted and the auxiliar Python files can be accessed from the Notebook. On how to allow your Notebook to find the .py files in your Google Drive, see instructions in this [link](https://nimbusintelligence.com/2023/03/import-python-scripts-in-google-colab/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-cg9BNEcma5w"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "# The path here can be different, depending on where you have uploaded the auxiliary Python files config.py, main.py, utils.py, model.py, visualise.py, data.py\n",
        "sys.path.insert(0,'/content/drive/My Drive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aogBdN1kXaWI"
      },
      "source": [
        "We start by importing a set of modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZECq2uAVUbw"
      },
      "outputs": [],
      "source": [
        "import dataclasses\n",
        "from typing import Optional, Tuple, Union, Callable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from pathlib import Path\n",
        "import gc\n",
        "import uuid\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppd49QmyX3Ns"
      },
      "outputs": [],
      "source": [
        "!pip install laplace-torch\n",
        "from laplace import Laplace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql9vxE4EZFq5"
      },
      "source": [
        "## 2.1 Preparing the dataset\n",
        "\n",
        "We work with the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef2Rt5ZEX3lG"
      },
      "outputs": [],
      "source": [
        "from data import get_data, prepare_data_loaders\n",
        "\n",
        "# Get preprocessed MNIST data\n",
        "data = get_data()\n",
        "\n",
        "# Create PyTorch DataLoaders\n",
        "train_loader, test_loader = prepare_data_loaders(data, batch_size=64)\n",
        "\n",
        "# Function to display a grid of images\n",
        "def display_mnist_samples(images, labels, grid_size=(3, 3)):\n",
        "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(8, 8))\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < len(images):\n",
        "            # Remove the extra dimension and display the image\n",
        "            ax.imshow(images[i].squeeze(), cmap='gray')\n",
        "            # Get the original label (not one-hot encoded)\n",
        "            label = np.argmax(labels[i])\n",
        "            ax.set_title(f\"Digit: {label}\")\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display a few samples from the training set\n",
        "num_samples = 9\n",
        "indices = np.random.choice(len(data.x_train), num_samples, replace=False)\n",
        "sample_images = data.x_train[indices]\n",
        "sample_labels = data.y_train[indices]\n",
        "\n",
        "# Display the images\n",
        "display_mnist_samples(sample_images, sample_labels)\n",
        "\n",
        "# Print some information about the dataset\n",
        "print(f\"Total training samples: {len(data.x_train)}\")\n",
        "print(f\"Total test samples: {len(data.x_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwDVDhuTebhP"
      },
      "source": [
        "## 2.2 Defining the model\n",
        "\n",
        "We can now define our model. We will use a small, simple Convolutional Neural Network with dropout as shown below:\n",
        "\n",
        "```\n",
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(3872, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        x = self.conv_layers(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "def build_model():\n",
        "    model = MNISTModel()\n",
        "    return model\n",
        "\n",
        "```\n",
        "This network model has been defined in the file `model.py` and we will call it later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJtxVA7Qm3oz"
      },
      "source": [
        "## 2.3 Defining the uncertainty functions\n",
        "\n",
        "### 2.3.1 Epistemic or knowledge uncertainty\n",
        "\n",
        "We will use epistemic uncertainty (also called knowledge\n",
        "uncertainty) as one of our main uncertainty functions to acquire new\n",
        "samples. Let us define the function to compute epistemic uncertainty\n",
        "over our predictions.\n",
        "\n",
        "We define the followoing terms and notations:\n",
        "- $\\omega$: Model parameters (weights and biases)\n",
        "- $p(y = c|x, \\omega)$: Probability of input $x$ belonging to class $c$ with model parameters $\\omega$\n",
        "- $q_\\theta^*(\\omega)$: Approximate posterior distribution over model parameters\n",
        "- $\\hat{\\omega}_t \\sim q_\\theta^*(\\omega)$: A sample of weights drawn from the approximate posterior\n",
        "- $\\hat{p}_c^t = p(y = c|x, \\hat{\\omega}_t)$: Predicted probability for class $c$ using sampled weights $\\hat{\\omega}_t$ in MC dropout\n",
        "- $T$: Total number of Monte Carlo dropout forward passes\n",
        "- $C$: Number of classes\n",
        "\n",
        "### Total Uncertainty\n",
        "\n",
        "The total predictive uncertainty is captured by the entropy of the expected predictive distribution (Max Entropy, (Shannon, 1948)):\n",
        "\n",
        "$$H[y|x, D_{\\text{train}}] = -\\sum_{c} p(y = c|x, D_{\\text{train}}) \\log p(y = c|x, D_{\\text{train}})$$\n",
        "\n",
        "This can be approximated using $T$ forward passes with MC dropout:\n",
        "\n",
        "$$H[y|x, D_{\\text{train}}] \\approx -\\sum_{c} \\left(\\frac{1}{T}\\sum_{t=1}^{T} \\hat{p}_c^t\\right) \\log \\left(\\frac{1}{T}\\sum_{t=1}^{T} \\hat{p}_c^t\\right)$$\n",
        "\n",
        "### Data Uncertainty (Aleatoric)\n",
        "\n",
        "Data uncertainty represents the inherent noise in the data, approximated as the expected entropy of individual predictions (Gal, 2016, pp. 48‚Äì52):\n",
        "\n",
        "$$E_{p(\\omega|D_{\\text{train}})}[H[y|x, \\omega]] \\approx \\frac{1}{T}\\sum_{t=1}^{T} \\left(-\\sum_{c} \\hat{p}_c^t \\log \\hat{p}_c^t\\right)$$\n",
        "\n",
        "### Knowledge Uncertainty (Epistemic)\n",
        "\n",
        "Knowledge uncertainty is the mutual information between predictions and model posterior, which is the BALD acquisition function (Houlsby et al., 2011) in the paper (which is Total `Uncertainty` - `Data Uncertainty`) :\n",
        "\n",
        "$$I[y, \\omega|x, D_{\\text{train}}] = H[y|x, D_{\\text{train}}] - E_{p(\\omega|D_{\\text{train}})}[H[y|x, \\omega]]$$\n",
        "\n",
        "This quantity represents the uncertainty in the model parameters, which can be reduced by acquiring more data. This is why it serves as an effective acquisition function for active learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX6dZv9docfe"
      },
      "source": [
        "Knowledge uncertainty will be used as acquisition function in the active learning loop. To compute it, we first need the weights obtained through MC dropout.\n",
        "\n",
        "`get_mc_predictions` uses MC droupout to generate the necessary prediction distribution (multiple predictions per sample) that the uncertainty functions need as input. It creates the `preds` tensor $\\hat{p}_c^t$ with shape (n_samples, n_mc_passes, n_classes) that is directly passed to `total_uncertainty`, `data_uncertainty`, and `knowledge_uncertainty`. Without these stochastic samples $\\hat{p}_c^t$ from dropout, we could not calculate these different uncertainty types for active learning sample selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5l4I5AKea0e"
      },
      "outputs": [],
      "source": [
        "def get_mc_predictions(model: nn.Module, n_iter: int, x_train: torch.Tensor) -> torch.Tensor:\n",
        "    device = next(model.parameters()).device\n",
        "    preds = []\n",
        "    # Set model to training mode to enable dropout\n",
        "    model.train()\n",
        "    with torch.no_grad():\n",
        "        for _ in tqdm(range(n_iter)):\n",
        "            # Split data into batches\n",
        "            preds_iter = []\n",
        "            for batch in torch.chunk(x_train, chunks=6):\n",
        "                batch = batch.to(device)\n",
        "                # Ensure input is float and has correct shape (add channel dim if needed)\n",
        "                if len(batch.shape) == 3:\n",
        "                    batch = batch.unsqueeze(1)\n",
        "                preds_iter.append(model(batch))\n",
        "            # Concatenate batch predictions\n",
        "            preds.append(torch.cat(preds_iter, dim=0))\n",
        "    # Stack predictions and move axes to get (n_images, n_predictions, n_classes)\n",
        "    preds = torch.stack(preds, dim=1)\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRBdrvHJrxa5"
      },
      "source": [
        "**Question 3 (10 marks)**\n",
        "\n",
        "Write the code for the functions `data_uncertainty` and `total_uncertainty` below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIFIwo0vsZ9O"
      },
      "source": [
        "*Solution*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUTwyZ5gsb8v"
      },
      "outputs": [],
      "source": [
        "def total_uncertainty(preds: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n",
        "    #\n",
        "    #\n",
        "    return\n",
        "\n",
        "def data_uncertainty(preds: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n",
        "    #\n",
        "    #\n",
        "    return\n",
        "\n",
        "def knowledge_uncertainty(preds: torch.Tensor, epsilon: float = 1e-10) -> torch.Tensor:\n",
        "    # Knowledge uncertainty is the difference between total and data uncertainty\n",
        "    return total_uncertainty(preds, epsilon) - data_uncertainty(preds, epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj1R4fJVunBJ"
      },
      "source": [
        "The acquisition function that uses the knowledge uncertainty function can be summarised in three steps\n",
        "1. Obtain an ensemble of predictions via MC dropout (done by `get_mc_predictions`).\n",
        "2. Compute the knowledge uncertainty values over this prediction\n",
        "ensemble (use `knowledge_uncertainty` function).\n",
        "3. Sort the uncertainty values, get their index and return the\n",
        "indices of the data in the pool with the highest epistemic\n",
        "uncertainty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xoliVEgvDjE"
      },
      "outputs": [],
      "source": [
        "def acquire_knowledge_uncertainty(\n",
        "    x_train: torch.Tensor, n_samples: int, model: nn.Module, n_iter: int, *args, **kwargs\n",
        "):\n",
        "    # Get Monte Carlo predictions\n",
        "    preds = get_mc_predictions(model, n_iter, x_train)\n",
        "    # Compute knowledge uncertainty\n",
        "    ku = knowledge_uncertainty(preds)\n",
        "    # Get indices of samples with highest uncertainty\n",
        "    _, indices = torch.topk(ku, n_samples)\n",
        "    return indices.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ2sLahwvb2G"
      },
      "source": [
        "### 2.3.2 Laplace uncertainty\n",
        "\n",
        "Rather than using MC dropout to compute samples on the parameters of the neural network, we can use a Laplace approximation, which approximates the posterior distribution of the parameters using a Gaussian distribution.\n",
        "\n",
        "The predictive distribution under a Bayesian approach (Gal, 2016) can be written as:\n",
        "\n",
        "$$p(y=c|x, D_{train}) = \\int p(y=c|x, \\omega)p(\\omega|D_{train})d\\omega.$$\n",
        "\n",
        "With Laplace approximation, we approximate the posterior $p(\\omega|D_{train})$ with a **Gaussian distribution** $N$ centered at the MAP estimate:\n",
        "\n",
        "$$p(\\omega|D_{train}) \\approx N(\\omega|\\omega_{MAP}, \\Sigma_{post}),$$\n",
        "\n",
        "where:\n",
        "- $\\omega_{MAP}$ is the maximum a posteriori estimate of the parameters\n",
        "- $\\Sigma_{post}$ is the covariance matrix computed at $\\omega_{MAP}$.\n",
        "\n",
        "We can then use this posterior distribution and the probit likelihood to approximate the posterior probabilities over the classes.\n",
        "\n",
        "Computing the Laplace approximation for a posterior distribution of a neural network is cumbersome in general. Here, we use a recent package known as [Laplace that allows to compute the posterior distribution effortlessly](https://github.com/AlexImmer/Laplace).\n",
        "\n",
        "### Uncertainty Measure for Acquisition when using the Laplace approximation\n",
        "\n",
        "We use Max Entropy (Shannon, 1948) as an uncertainty measure in this case:\n",
        "\n",
        "$$H[y|x, D_{train}] := -\\sum_{c} p(y=c|x, D_{train}) \\log p(y=c|x, D_{train})$$\n",
        "\n",
        "This acquisition function selects pool points that maximize the predictive entropy.\n",
        "\n",
        "The acquisition function that uses the max entropy with Laplace approximation can be summarised in three steps\n",
        "1. Obtain the predictions under the posterior distribution via Laplace approximation.\n",
        "2. Compute the max entropy values for the datapoints in the pool.\n",
        "3. Sort the uncertainty values, get their index and return the\n",
        "indices of the data in the pool with the highest epistemic\n",
        "uncertainty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b79xKKJ_y28d"
      },
      "source": [
        "**Question 4 (10 marks)**\n",
        "\n",
        "The following acquisition function implements the three steps above. Write the code for steps 1 and 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrKP59HFzY3a"
      },
      "source": [
        "*Solution*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vel9qdWnzetR"
      },
      "outputs": [],
      "source": [
        "def acquire_laplace_uncertainty(\n",
        "    unlabeled_tensor: torch.Tensor, n_samples: int, la_model: Laplace) -> np.ndarray:\n",
        "    try:\n",
        "        # Step 1: Predict probabilities with error handling\n",
        "        #\n",
        "        # Convert to numpy with checks\n",
        "        try:\n",
        "            preds_np = preds.numpy()\n",
        "        except Exception:\n",
        "            preds_np = preds.detach().cpu().numpy()\n",
        "\n",
        "        # Step 2: Entropy calculation\n",
        "        #\n",
        "        #\n",
        "\n",
        "        # Step 3: Select indices with highest uncertainty\n",
        "        indices = np.argsort(uncertainty)[-n_samples:]\n",
        "        return indices\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Laplace Acquisition Error: {e}\")\n",
        "        # Fallback to random sampling\n",
        "        return np.random.choice(len(unlabeled_tensor), n_samples, replace=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4kW5teXvV0G"
      },
      "source": [
        "### 2.3.3 Random selection\n",
        "\n",
        "The simplest approach to select a datapoint from the pool is to do it randomly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcYSrEflv6yB"
      },
      "outputs": [],
      "source": [
        "def acquire_random(x_train: torch.Tensor, n_samples: int, *args, **kwargs) -> np.ndarray:\n",
        "    # Randomly select samples\n",
        "    return torch.randperm(len(x_train))[:n_samples].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBxvOwlC0VF9"
      },
      "source": [
        "### 2.3.4 A battery of acquisition functions\n",
        "\n",
        "We can group the three acquisition functions above in a function,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9XaUHhP0i9I"
      },
      "outputs": [],
      "source": [
        "def acquisition_factory(acquisition_type: str) -> Callable:\n",
        "    if acquisition_type == \"laplace_uncertainty\":\n",
        "        return acquire_laplace_uncertainty\n",
        "    if acquisition_type == \"knowledge_uncertainty\":\n",
        "        return acquire_knowledge_uncertainty\n",
        "    elif acquisition_type == \"random\":\n",
        "        return acquire_random\n",
        "    else:\n",
        "        raise ValueError(f\"Acquisition type {acquisition_type} not supported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKVgY-nj1FNy"
      },
      "source": [
        "Now that we have defined our acquisition functions, we are ready\n",
        "to define the loop that runs the active learning iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXLq8vB71Sdy"
      },
      "source": [
        "## 2.4 Main Loop for Active Learning\n",
        "\n",
        "We will start our dataset with 20 samples until we reach a total of 500 samples. Each model will be trained for 25 epochs and per iteration, we acquire 10 samples. To obtain our MC dropout predictions, we will run over\n",
        "our full training set (minus the already acquired samples) 48 times.\n",
        "\n",
        "It will take you approx. 1 hour to finish the active learning loop using standard colab T4 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h0GbKNr07QC"
      },
      "outputs": [],
      "source": [
        "import main\n",
        "main.acquisition_factory= acquisition_factory #Put your acquisition functions inside the main module\n",
        "from main import Active_learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0-JRBWt51ar"
      },
      "outputs": [],
      "source": [
        "# Run Active Learning on Laplace Uncertainty Acquisition\n",
        "accuracies_l, added_indices_l = Active_learning(\n",
        "    acquisition_type=\"laplace_uncertainty\",\n",
        "    n_epochs=50,\n",
        "    n_samples_per_iter=10,\n",
        "    initial_n_samples=20,\n",
        "    n_total_samples=500,\n",
        "    use_wandb=False\n",
        ")\n",
        "\n",
        "# Run Active Learning on Random Acquisition\n",
        "accuracies_r, added_indices_r = Active_learning(\n",
        "    acquisition_type=\"random\",\n",
        "    n_epochs=50,\n",
        "    n_samples_per_iter=10,\n",
        "    initial_n_samples=20,\n",
        "    n_total_samples=500,\n",
        "    use_wandb=False\n",
        ")\n",
        "\n",
        "# Run Active Learning on Knowlege Uncertainty Acquisition\n",
        "accuracies_k, added_indices_k = Active_learning(\n",
        "   acquisition_type=\"knowledge_uncertainty\",\n",
        "    n_epochs=50,\n",
        "    n_samples_per_iter=10,\n",
        "    initial_n_samples=20,\n",
        "    n_total_samples=500,\n",
        "    use_wandb=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXaAAe5R0Opy"
      },
      "source": [
        "### 2.5  Visualise the Results\n",
        "\n",
        "Now that we have our loop, we can inspect the results of this\n",
        "process. We will use seaborn and matplotlib to visualize our\n",
        "results. The main result we are interested in is the test accuracy over time\n",
        "for both the models trained with a random acquisition function and\n",
        "the models trained with data acquired via knowledge uncertainty.\n",
        "To visualize this, we define `ActiveLearningVisualizer` that loads the results and\n",
        "then returns a plot that shows the accuracy per active learning\n",
        "iteration cycle.\n",
        "\n",
        "We can then use this function to plot the results for all acquisition\n",
        "functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIDK-GgxBBFH"
      },
      "outputs": [],
      "source": [
        "from visualise import ActiveLearningVisualizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize visualizer\n",
        "visualizer = ActiveLearningVisualizer(output_dir=\"output\", samples_per_iter=10, initial_samples=20)\n",
        "\n",
        "# Compare different acquisition strategies\n",
        "# IMPORTANT: change the uuids according to the ones assigned to each of the models trained\n",
        "fig_acc, fig_img, imgs = visualizer.compare_from_uuids(\n",
        "    uuids=[\"f911b431-3db2-422f-b2fe-fe5908c38178\",\n",
        "            \"3431804b-e582-48ba-a8e2-872c87c63146\",\n",
        "            \"2dcb6f4f-495e-4b5c-b50c-03daedcd1ef2\"],\n",
        "    acquisition_types=[\"laplace_uncertainty\", \"random\", \"knowledge_uncertainty\"]\n",
        ")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-QJAhQhOX2L"
      },
      "source": [
        "**Question 5 (10 marks)**\n",
        "\n",
        "- What can you conclude from the figure that shows the Accuracy of the different acquisition strategies? (**5 marks**). Use a single sentence.\n",
        "\n",
        "*Solution*\n",
        "\n",
        "Write your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What can you conclude when comparing the samples of the digits chosen for training by the different Acquisition strategies? (**5 marks**). Use a single sentence.\n",
        "\n",
        "*Solution*\n",
        "\n",
        "Write your answer here"
      ],
      "metadata": {
        "id": "7fLnXe1gYgrE"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}